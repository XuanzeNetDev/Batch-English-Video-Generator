#!/usr/bin/env python3
"""
å¡æ‹‰OKå¯¹é½å­—å¹•ç”Ÿæˆå™¨ - é€è¯é«˜äº®è·Ÿè¸ª
è§£å†³å­—å¹•ç²¾åº¦é—®é¢˜ + æ·»åŠ é¢œè‰²è·Ÿè¸ªæœ—è¯»æ•ˆæœ
ä½¿ç”¨ torchaudio Forced Alignment å®ç°ç²¾ç¡®å¯¹é½
"""

import os
import numpy as np
from pathlib import Path
import librosa
import re
import moviepy as mp
from PIL import Image, ImageDraw, ImageFont
import cv2
from difflib import SequenceMatcher
import platform

# PyTorch for forced alignment
import torch
import torchaudio


class KaraokeAlignmentGenerator:
    """å¡æ‹‰OKå¯¹é½å­—å¹•ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.output_dir = Path("karaoke_alignment_videos")
        self.output_dir.mkdir(exist_ok=True)
        
        self.temp_dir = Path("temp_karaoke_alignment")
        self.temp_dir.mkdir(exist_ok=True)
        
        self.audio_dir = Path("Stories_audio")
        self.english_dir = Path("English_Stories")
        self.chinese_dir = Path("Chinese_Stories")
        
        # é¢œè‰²é…ç½® - ç¬¬ä¸€ä¸ªæ•…äº‹ç”¨å†°è“è‰²ï¼Œå…¶ä»–éšæœº
        self.color_scheme = None
        
        # è®¾å¤‡é…ç½®
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print("ğŸ¤ å¡æ‹‰OKå¯¹é½å­—å¹•ç”Ÿæˆå™¨åˆå§‹åŒ–")
        print(f"   è®¾å¤‡: {self.device}")
    
    def get_system_font(self, size):
        """è·¨å¹³å°è·å–ç³»ç»Ÿå­—ä½“"""
        system = platform.system()
        
        try:
            if system == "Windows":
                # Windows å­—ä½“
                font_paths = [
                    "C:\\Windows\\Fonts\\simsun.ttc",
                    "C:\\Windows\\Fonts\\msyh.ttc",
                    "C:\\Windows\\Fonts\\arial.ttf"
                ]
            elif system == "Darwin":  # macOS
                font_paths = [
                    "/System/Library/Fonts/PingFang.ttc",
                    "/System/Library/Fonts/Helvetica.ttc",
                    "/Library/Fonts/Arial Unicode.ttf"
                ]
            else:  # Linux
                font_paths = [
                    "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
                    "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
                    "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"
                ]
            
            # å°è¯•åŠ è½½å­—ä½“
            for font_path in font_paths:
                if os.path.exists(font_path):
                    return ImageFont.truetype(font_path, size)
            
            # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
            print(f"âš ï¸ æœªæ‰¾åˆ°ç³»ç»Ÿå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
            return ImageFont.load_default()
            
        except Exception as e:
            print(f"âš ï¸ å­—ä½“åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
            return ImageFont.load_default()
    
    def extract_word_timestamps_with_forced_alignment(self, audio_path: str, english_text: str) -> list:
        """ä½¿ç”¨ torchaudio Forced Alignment æå–ç²¾ç¡®è¯çº§æ—¶é—´æˆ³
        
        å…³é”®æ”¹è¿›ï¼šä½¿ç”¨åŸæ–‡æ–‡æœ¬è¿›è¡Œå¼ºåˆ¶å¯¹é½ï¼Œè€Œä¸æ˜¯ä¾èµ– Whisper çš„è¯†åˆ«ç»“æœ
        è¿™æ ·å¯ä»¥è§£å†³æ•°å­—è¯†åˆ«ä¸ä¸€è‡´çš„é—®é¢˜ï¼ˆå¦‚ "two hundred" vs "200"ï¼‰
        """
        print("ğŸ¤ ä½¿ç”¨ torchaudio Forced Alignment æå–è¯çº§æ—¶é—´æˆ³...")
        
        # åŠ è½½ wav2vec2 æ¨¡å‹
        print("   ğŸ“ Step 1: åŠ è½½ wav2vec2 å¯¹é½æ¨¡å‹...")
        bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H
        model = bundle.get_model().to(self.device)
        labels = bundle.get_labels()
        
        # æ„å»ºå­—å…¸
        dictionary = {c.lower(): i for i, c in enumerate(labels)}
        
        # åŠ è½½éŸ³é¢‘
        print("   ğŸ“ Step 2: åŠ è½½éŸ³é¢‘...")
        import soundfile as sf
        audio_data, sample_rate = sf.read(audio_path)
        waveform = torch.tensor(audio_data).float()
        if len(waveform.shape) == 1:
            waveform = waveform.unsqueeze(0)
        elif waveform.shape[1] == 2:  # stereo to mono
            waveform = waveform.mean(dim=1, keepdim=True).T
        
        # é‡é‡‡æ ·åˆ°æ¨¡å‹éœ€è¦çš„é‡‡æ ·ç‡
        if sample_rate != bundle.sample_rate:
            waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)
        
        waveform = waveform.to(self.device)
        
        # è·å–æ¨¡å‹è¾“å‡º
        print("   ğŸ“ Step 3: è·å–å£°å­¦ç‰¹å¾...")
        with torch.inference_mode():
            emissions, _ = model(waveform)
            emissions = torch.log_softmax(emissions, dim=-1)
        
        emission = emissions[0].cpu().detach()
        
        # å‡†å¤‡æ–‡æœ¬
        # å°†æ–‡æœ¬è½¬æ¢ä¸º token åºåˆ—
        transcript = self._prepare_transcript(english_text, dictionary)
        tokens = [dictionary.get(c, 0) for c in transcript]
        
        print(f"   ğŸ“ Step 4: æ‰§è¡Œå¼ºåˆ¶å¯¹é½ ({len(tokens)} tokens)...")
        
        # æ„å»º trellis çŸ©é˜µ
        trellis = self._get_trellis(emission, tokens)
        
        # å›æº¯æ‰¾åˆ°æœ€ä½³è·¯å¾„
        path = self._backtrack(trellis, emission, tokens)
        
        if path is None:
            print("   âš ï¸ å¼ºåˆ¶å¯¹é½å¤±è´¥ï¼Œå›é€€åˆ° Whisper æ–¹æ³•")
            return self.extract_word_timestamps(audio_path)
        
        # åˆå¹¶é‡å¤çš„å­—ç¬¦
        segments = self._merge_repeats(path, transcript)
        
        # å°†å­—ç¬¦çº§æ—¶é—´æˆ³è½¬æ¢ä¸ºè¯çº§æ—¶é—´æˆ³
        word_segments = self._chars_to_words(segments, english_text, emission.shape[0], bundle.sample_rate)
        
        print(f"   âœ… æå– {len(word_segments)} ä¸ªè¯çš„ç²¾ç¡®æ—¶é—´æˆ³")
        
        # æ¸…ç†
        del model
        if self.device == "cuda":
            torch.cuda.empty_cache()
        
        return word_segments
    
    def _prepare_transcript(self, text: str, dictionary: dict) -> str:
        """å‡†å¤‡ç”¨äºå¯¹é½çš„è½¬å½•æ–‡æœ¬"""
        # è½¬æ¢ä¸ºå°å†™ï¼Œç”¨ | è¡¨ç¤ºç©ºæ ¼
        result = []
        text = text.lower()
        
        for char in text:
            if char == ' ':
                result.append('|')
            elif char in dictionary:
                result.append(char)
            # è·³è¿‡ä¸åœ¨å­—å…¸ä¸­çš„å­—ç¬¦ï¼ˆæ ‡ç‚¹ç­‰ï¼‰
        
        return ''.join(result)
    
    def _get_trellis(self, emission, tokens, blank_id=0):
        """æ„å»º trellis çŸ©é˜µ"""
        num_frame = emission.size(0)
        num_tokens = len(tokens)
        
        trellis = torch.zeros((num_frame, num_tokens))
        trellis[1:, 0] = torch.cumsum(emission[1:, blank_id], 0)
        trellis[0, 1:] = -float("inf")
        trellis[-num_tokens + 1:, 0] = float("inf")
        
        for t in range(num_frame - 1):
            trellis[t + 1, 1:] = torch.maximum(
                trellis[t, 1:] + emission[t, blank_id],
                trellis[t, :-1] + emission[t, tokens[1:]],
            )
        return trellis
    
    def _backtrack(self, trellis, emission, tokens, blank_id=0):
        """å›æº¯æ‰¾åˆ°æœ€ä½³è·¯å¾„"""
        t, j = trellis.size(0) - 1, trellis.size(1) - 1
        
        path = [{'token_index': j, 'time_index': t, 'score': emission[t, blank_id].exp().item()}]
        
        while j > 0:
            if t <= 0:
                return None
            
            p_stay = emission[t - 1, blank_id]
            p_change = emission[t - 1, tokens[j]]
            
            stayed = trellis[t - 1, j] + p_stay
            changed = trellis[t - 1, j - 1] + p_change
            
            t -= 1
            if changed > stayed:
                j -= 1
            
            prob = (p_change if changed > stayed else p_stay).exp().item()
            path.append({'token_index': j, 'time_index': t, 'score': prob})
        
        while t > 0:
            prob = emission[t - 1, blank_id].exp().item()
            path.append({'token_index': j, 'time_index': t - 1, 'score': prob})
            t -= 1
        
        return path[::-1]
    
    def _merge_repeats(self, path, transcript):
        """åˆå¹¶é‡å¤çš„å­—ç¬¦"""
        segments = []
        i1, i2 = 0, 0
        
        while i1 < len(path):
            while i2 < len(path) and path[i1]['token_index'] == path[i2]['token_index']:
                i2 += 1
            
            score = sum(p['score'] for p in path[i1:i2]) / (i2 - i1)
            
            segments.append({
                'label': transcript[path[i1]['token_index']],
                'start': path[i1]['time_index'],
                'end': path[i2 - 1]['time_index'] + 1,
                'score': score
            })
            
            i1 = i2
        
        return segments
    
    def _chars_to_words(self, char_segments, original_text: str, num_frames: int, sample_rate: int) -> list:
        """å°†å­—ç¬¦çº§æ—¶é—´æˆ³è½¬æ¢ä¸ºè¯çº§æ—¶é—´æˆ³"""
        # è®¡ç®—æ—¶é—´æ¯”ä¾‹
        ratio = len(original_text) / num_frames if num_frames > 0 else 1
        
        # åˆ†è¯
        words = original_text.split()
        word_segments = []
        
        char_idx = 0
        for word in words:
            word_lower = word.lower()
            
            # æ‰¾åˆ°è¿™ä¸ªè¯å¯¹åº”çš„å­—ç¬¦æ®µ
            word_start = None
            word_end = None
            word_score = []
            
            for char in word_lower:
                if char in 'abcdefghijklmnopqrstuvwxyz':
                    # åœ¨ char_segments ä¸­æŸ¥æ‰¾
                    while char_idx < len(char_segments):
                        seg = char_segments[char_idx]
                        if seg['label'] == char:
                            if word_start is None:
                                word_start = seg['start']
                            word_end = seg['end']
                            word_score.append(seg['score'])
                            char_idx += 1
                            break
                        elif seg['label'] == '|':
                            char_idx += 1
                        else:
                            char_idx += 1
            
            # è½¬æ¢ä¸ºç§’
            if word_start is not None and word_end is not None:
                # æ¯å¸§çº¦ 20ms (50 fps)
                frame_duration = 0.02
                word_segments.append({
                    'word': word,
                    'start': word_start * frame_duration,
                    'end': word_end * frame_duration,
                    'score': sum(word_score) / len(word_score) if word_score else 0.5
                })
            else:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨ä¼°ç®—
                if word_segments:
                    last_end = word_segments[-1]['end']
                else:
                    last_end = 0
                
                word_segments.append({
                    'word': word,
                    'start': last_end,
                    'end': last_end + 0.3,
                    'score': 0.3
                })
        
        return word_segments
    
    def extract_word_timestamps(self, audio_path: str) -> list:
        """æå–è¯çº§æ—¶é—´æˆ³ - ä½¿ç”¨ Whisperï¼ˆæ—§æ–¹æ³•ï¼Œä¿ç•™å…¼å®¹ï¼‰"""
        print("ğŸ¤ æå–è¯çº§æ—¶é—´æˆ³ï¼ˆWhisperæ–¹æ³•ï¼‰...")
        
        import whisper
        model = whisper.load_model("base")
        result = model.transcribe(
            audio_path, 
            word_timestamps=True, 
            language='en',
            temperature=0.0
        )
        
        word_segments = []
        for segment in result["segments"]:
            if "words" in segment:
                for word_info in segment["words"]:
                    word_segments.append({
                        'word': word_info['word'].strip(),
                        'start': word_info['start'],
                        'end': word_info['end']
                    })
        
        print(f"   âœ… æå– {len(word_segments)} ä¸ªæ—¶é—´æˆ³")
        return word_segments
    
    def load_stories(self, story_num: int) -> tuple:
        """åŠ è½½åŸæ–‡ - è‹±æ–‡å’Œä¸­æ–‡ï¼ˆæ”¯æŒä¸€å¥ä¸€è¡Œæ ¼å¼ï¼‰"""
        print("ğŸ“ åŠ è½½åŸæ–‡...")
        
        # è‹±æ–‡åŸæ–‡
        eng_files = sorted(list(self.english_dir.glob("*.txt")))
        with open(eng_files[story_num - 1], 'r', encoding='utf-8') as f:
            eng_lines = f.readlines()
        
        # ä¸­æ–‡ç¿»è¯‘
        chi_files = sorted(list(self.chinese_dir.glob("*.txt")))
        with open(chi_files[story_num - 1], 'r', encoding='utf-8') as f:
            chi_lines = f.readlines()
        
        # æå–å¥å­ï¼ˆè·³è¿‡æ ‡é¢˜å’Œç©ºè¡Œï¼‰
        # æ ¼å¼ï¼šæ ‡é¢˜ + ç©ºè¡Œ + æ¯å¥ä¸€è¡Œ
        eng_sentences = []
        chi_sentences = []
        
        # è·³è¿‡ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜ï¼‰å’Œç¬¬äºŒè¡Œï¼ˆç©ºè¡Œï¼‰
        for line in eng_lines[2:]:
            line = line.strip()
            if line:  # è·³è¿‡ç©ºè¡Œ
                eng_sentences.append(line)
        
        for line in chi_lines[2:]:
            line = line.strip()
            if line:  # è·³è¿‡ç©ºè¡Œ
                chi_sentences.append(line)
        
        print(f"   âœ… {len(eng_sentences)} ä¸ªè‹±æ–‡å¥å­")
        print(f"   âœ… {len(chi_sentences)} ä¸ªä¸­æ–‡å¥å­")
        
        # æ£€æŸ¥å¥å­æ•°é‡æ˜¯å¦åŒ¹é…
        if len(eng_sentences) != len(chi_sentences):
            print(f"   âš ï¸  è­¦å‘Š: ä¸­è‹±æ–‡å¥å­æ•°é‡ä¸åŒ¹é…!")
            print(f"      è‹±æ–‡: {len(eng_sentences)}å¥")
            print(f"      ä¸­æ–‡: {len(chi_sentences)}å¥")
        
        return eng_sentences, chi_sentences
    
    def align_sentences_with_forced_alignment(self, word_timestamps: list, eng_sentences: list, chi_sentences: list) -> list:
        """ä½¿ç”¨ Forced Alignment ç»“æœè¿›è¡Œå¥å­å¯¹é½
        
        word_timestamps å·²ç»æ˜¯ç²¾ç¡®å¯¹é½åˆ°åŸæ–‡çš„æ—¶é—´æˆ³ï¼Œç›´æ¥æŒ‰å¥å­åˆ†ç»„å³å¯
        """
        print("ğŸ¯ ä½¿ç”¨ Forced Alignment ç»“æœå¯¹é½å¥å­...")
        
        # æ„å»ºè¯åˆ°å¥å­çš„æ˜ å°„
        all_original_words = []
        word_to_sentence = []
        
        for i, sent in enumerate(eng_sentences):
            words = sent.split()
            for word in words:
                all_original_words.append(word)
                word_to_sentence.append(i)
        
        print(f"   ğŸ“Š åŸæ–‡æ€»è¯æ•°: {len(all_original_words)}")
        print(f"   ğŸ“Š å¯¹é½æ—¶é—´æˆ³æ•°: {len(word_timestamps)}")
        
        # æ£€æŸ¥è¯æ•°æ˜¯å¦åŒ¹é…
        if len(word_timestamps) != len(all_original_words):
            print(f"   âš ï¸ è¯æ•°ä¸å®Œå…¨åŒ¹é…ï¼Œå°è¯•æ™ºèƒ½å¯¹é½...")
            # å¦‚æœä¸åŒ¹é…ï¼Œä½¿ç”¨æ¨¡ç³ŠåŒ¹é…
            return self.align_sentences_fuzzy(word_timestamps, eng_sentences, chi_sentences, all_original_words, word_to_sentence)
        
        # è¯æ•°åŒ¹é…ï¼Œç›´æ¥åˆ†é…
        aligned_words = []
        for i, (word, ts) in enumerate(zip(all_original_words, word_timestamps)):
            aligned_words.append({
                'word': word,  # ä½¿ç”¨åŸæ–‡çš„è¯
                'start': ts['start'],
                'end': ts['end'],
                'score': ts.get('score', 1.0),
                'sentence_idx': word_to_sentence[i]
            })
        
        # æŒ‰å¥å­ç»„ç»‡
        aligned = []
        for i, eng_sent in enumerate(eng_sentences):
            sentence_words = [w for w in aligned_words if w['sentence_idx'] == i]
            
            if sentence_words:
                start_time = sentence_words[0]['start']
                end_time = sentence_words[-1]['end']
            else:
                start_time = 0
                end_time = 0
            
            chi_text = chi_sentences[i] if i < len(chi_sentences) else ""
            
            aligned.append({
                'index': i + 1,
                'start': start_time,
                'end': end_time,
                'english': eng_sent,
                'chinese': chi_text,
                'words': sentence_words,
                'score': 1.0,
                'word_start_idx': 0,
                'word_end_idx': len(sentence_words) - 1
            })
            
            if i < 5 or i >= len(eng_sentences) - 3:
                print(f"   ğŸ¯ {i+1}: {start_time:.2f}s-{end_time:.2f}s, {len(sentence_words)} è¯")
        
        print(f"   âœ… {len(aligned)} ä¸ªå¥å­å¯¹é½å®Œæˆ")
        return aligned
    
    def align_sentences_fuzzy(self, word_timestamps: list, eng_sentences: list, chi_sentences: list, 
                               all_original_words: list, word_to_sentence: list) -> list:
        """æ¨¡ç³Šå¯¹é½ - å½“è¯æ•°ä¸å®Œå…¨åŒ¹é…æ—¶ä½¿ç”¨"""
        print("   ğŸ”„ ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…å¯¹é½...")
        
        # ä½¿ç”¨åºåˆ—åŒ¹é…æ‰¾åˆ°æœ€ä½³å¯¹é½
        ts_words = [ts['word'].lower().strip('.,!?;:"\'') for ts in word_timestamps]
        orig_words = [w.lower().strip('.,!?;:"\'') for w in all_original_words]
        
        # æ„å»ºå¯¹é½æ˜ å°„
        aligned_words = []
        ts_idx = 0
        
        for i, orig_word in enumerate(all_original_words):
            orig_clean = orig_word.lower().strip('.,!?;:"\'')
            
            # åœ¨æ—¶é—´æˆ³ä¸­æŸ¥æ‰¾åŒ¹é…
            best_match_idx = ts_idx
            best_score = 0
            
            # åœ¨å½“å‰ä½ç½®é™„è¿‘æœç´¢
            search_range = min(5, len(word_timestamps) - ts_idx)
            for j in range(search_range):
                if ts_idx + j >= len(word_timestamps):
                    break
                ts_clean = ts_words[ts_idx + j]
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                if orig_clean == ts_clean:
                    score = 1.0
                elif orig_clean in ts_clean or ts_clean in orig_clean:
                    score = 0.8
                else:
                    score = SequenceMatcher(None, orig_clean, ts_clean).ratio()
                
                if score > best_score:
                    best_score = score
                    best_match_idx = ts_idx + j
            
            # ä½¿ç”¨æ‰¾åˆ°çš„æ—¶é—´æˆ³
            if best_match_idx < len(word_timestamps):
                ts = word_timestamps[best_match_idx]
                aligned_words.append({
                    'word': orig_word,
                    'start': ts['start'],
                    'end': ts['end'],
                    'score': best_score,
                    'sentence_idx': word_to_sentence[i]
                })
                ts_idx = best_match_idx + 1
            else:
                # æ²¡æœ‰æ›´å¤šæ—¶é—´æˆ³ï¼Œä½¿ç”¨ä¼°ç®—
                if aligned_words:
                    last_end = aligned_words[-1]['end']
                    avg_duration = 0.3  # å¹³å‡è¯æ—¶é•¿
                    aligned_words.append({
                        'word': orig_word,
                        'start': last_end,
                        'end': last_end + avg_duration,
                        'score': 0.5,
                        'sentence_idx': word_to_sentence[i]
                    })
        
        # æŒ‰å¥å­ç»„ç»‡
        aligned = []
        for i, eng_sent in enumerate(eng_sentences):
            sentence_words = [w for w in aligned_words if w['sentence_idx'] == i]
            
            if sentence_words:
                start_time = sentence_words[0]['start']
                end_time = sentence_words[-1]['end']
            else:
                start_time = aligned[-1]['end'] if aligned else 0
                end_time = start_time
            
            chi_text = chi_sentences[i] if i < len(chi_sentences) else ""
            
            aligned.append({
                'index': i + 1,
                'start': start_time,
                'end': end_time,
                'english': eng_sent,
                'chinese': chi_text,
                'words': sentence_words,
                'score': sum(w['score'] for w in sentence_words) / len(sentence_words) if sentence_words else 0,
                'word_start_idx': 0,
                'word_end_idx': len(sentence_words) - 1
            })
            
            if i < 5 or i >= len(eng_sentences) - 3:
                avg_score = aligned[-1]['score']
                print(f"   ğŸ¯ {i+1}: {start_time:.2f}s-{end_time:.2f}s, {len(sentence_words)} è¯, ç½®ä¿¡åº¦ {avg_score:.0%}")
        
        print(f"   âœ… {len(aligned)} ä¸ªå¥å­å¯¹é½å®Œæˆ")
        return aligned
    
    def align_sentences(self, word_timestamps: list, eng_sentences: list, chi_sentences: list) -> list:
        """æ™ºèƒ½å¯¹é½ - ä½¿ç”¨Whisperæ—¶é—´æˆ³ï¼ŒåŠ¨æ€åˆ†é…ç»™åŸæ–‡è¯"""
        print("ğŸ¯ æ™ºèƒ½å¯¹é½ï¼ˆåŠ¨æ€æ—¶é—´åˆ†é…ï¼‰...")
        
        # æå–æ‰€æœ‰åŸæ–‡è¯
        all_original_words = []
        word_to_sentence = []
        
        for i, sent in enumerate(eng_sentences):
            words = sent.split()
            for word in words:
                all_original_words.append(word)
                word_to_sentence.append(i)
        
        print(f"   ğŸ“Š åŸæ–‡æ€»è¯æ•°: {len(all_original_words)}")
        print(f"   ğŸ“Š Whisperæ—¶é—´æˆ³æ•°: {len(word_timestamps)}")
        
        # ä½¿ç”¨Whisperçš„æ€»æ—¶é•¿ï¼ŒæŒ‰åŸæ–‡è¯æ•°åˆ†é…
        if len(word_timestamps) > 0:
            total_duration = word_timestamps[-1]['end'] - word_timestamps[0]['start']
            avg_duration_per_word = total_duration / len(all_original_words)
            
            print(f"   ğŸ“Š æ€»æ—¶é•¿: {total_duration:.2f}ç§’")
            print(f"   ğŸ“Š å¹³å‡æ¯è¯: {avg_duration_per_word:.2f}ç§’")
        
        # ä¸ºæ¯ä¸ªåŸæ–‡è¯åˆ†é…æ—¶é—´
        aligned_words = []
        current_time = word_timestamps[0]['start'] if word_timestamps else 0
        
        for i, word in enumerate(all_original_words):
            # ä½¿ç”¨å¹³å‡æ—¶é•¿
            start_time = current_time
            end_time = current_time + avg_duration_per_word
            
            # ä½†å¦‚æœæœ‰å¯¹åº”çš„Whisperæ—¶é—´æˆ³ï¼Œä¼˜å…ˆä½¿ç”¨
            if i < len(word_timestamps):
                # ä½¿ç”¨Whisperçš„æ—¶é—´æˆ³ä½œä¸ºå‚è€ƒ
                whisper_duration = word_timestamps[i]['end'] - word_timestamps[i]['start']
                end_time = start_time + whisper_duration
            
            aligned_words.append({
                'word': word,
                'start': start_time,
                'end': end_time,
                'sentence_idx': word_to_sentence[i]
            })
            
            current_time = end_time
        
        # æŒ‰å¥å­é‡æ–°ç»„ç»‡
        aligned = []
        
        for i, eng_sent in enumerate(eng_sentences):
            sentence_words = [w for w in aligned_words if w['sentence_idx'] == i]
            
            if sentence_words:
                start_time = sentence_words[0]['start']
                end_time = sentence_words[-1]['end']
            else:
                start_time = 0
                end_time = 0
            
            chi_text = chi_sentences[i] if i < len(chi_sentences) else ""
            
            aligned.append({
                'index': i + 1,
                'start': start_time,
                'end': end_time,
                'english': eng_sent,
                'chinese': chi_text,
                'words': sentence_words,
                'score': 1.0,
                'word_start_idx': 0,
                'word_end_idx': len(sentence_words) - 1
            })
            
            if i < 5 or i >= len(eng_sentences) - 3:
                print(f"   ğŸ¯ {i+1}: {start_time:.2f}s-{end_time:.2f}s, {len(sentence_words)} è¯")
        
        print(f"   âœ… {len(aligned)} ä¸ªå¥å­å¯¹é½å®Œæˆ")
        
        total_assigned = sum(len(s['words']) for s in aligned)
        print(f"   ğŸ“Š åˆ†é…äº† {total_assigned}/{len(all_original_words)} ä¸ªè¯")
        
        return aligned
        """æ™ºèƒ½å¯¹é½ - ç¡®ä¿æ‰€æœ‰è¯éƒ½è¢«ä½¿ç”¨"""
        print("ğŸ¯ æ™ºèƒ½å¯¹é½...")
        
        aligned = []
        word_idx = 0
        total_words = len(word_segments)
        total_sentences = len(eng_sentences)
        
        for i, eng_sent in enumerate(eng_sentences):
            # è·å–å¥å­çš„è¯
            sent_words = eng_sent.split()
            expected_words = len(sent_words)
            
            # è®¡ç®—å‰©ä½™çš„è¯å’Œå¥å­
            remaining_sentences = total_sentences - i
            remaining_words = max(0, total_words - word_idx)
            
            # å¦‚æœè¯å·²ç»ç”¨å®Œï¼Œä½†è¿˜æœ‰å¥å­ï¼Œç»™ä¸€ä¸ªç©ºçš„å¯¹é½
            if word_idx >= len(word_segments):
                aligned.append({
                    'index': i + 1,
                    'start': aligned[-1]['end'] if aligned else 0,
                    'end': aligned[-1]['end'] if aligned else 0,
                    'english': eng_sent,
                    'chinese': chi_sentences[i] if i < len(chi_sentences) else "",
                    'words': [],
                    'score': 0,
                    'word_start_idx': len(word_segments) - 1,
                    'word_end_idx': len(word_segments) - 1
                })
                continue
            
            # ä»å½“å‰ä½ç½®å¼€å§‹åŒ¹é…
            best_start = word_idx
            best_end = word_idx
            matched_count = 0
            
            # å°è¯•åŒ¹é…å¥å­ä¸­çš„æ¯ä¸ªè¯
            current_idx = word_idx
            for sent_word in sent_words:
                if current_idx >= len(word_segments):
                    break
                
                # æ¸…ç†æ ‡ç‚¹
                sent_word_clean = sent_word.lower().strip('.,!?;:"\'')
                
                # åœ¨æ¥ä¸‹æ¥çš„3ä¸ªè¯ä¸­æŸ¥æ‰¾åŒ¹é…
                found = False
                for look_ahead in range(3):
                    if current_idx + look_ahead >= len(word_segments):
                        break
                    
                    whisper_word = word_segments[current_idx + look_ahead]['word'].lower().strip('.,!?;:"\'')
                    
                    if (sent_word_clean == whisper_word or 
                        sent_word_clean in whisper_word or 
                        whisper_word in sent_word_clean):
                        matched_count += 1
                        current_idx = current_idx + look_ahead + 1
                        best_end = current_idx - 1
                        found = True
                        break
                
                if not found:
                    # æ²¡æ‰¾åˆ°ï¼Œè·³è¿‡è¿™ä¸ªè¯
                    current_idx += 1
            
            # å¦‚æœåŒ¹é…ç‡å¤ªä½ï¼Œä½¿ç”¨å¹³å‡åˆ†é…ç­–ç•¥
            match_rate = matched_count / len(sent_words) if sent_words else 0
            
            if match_rate < 0.3 or best_end < best_start:
                # æŒ‰å‰©ä½™è¯æ•°å¹³å‡åˆ†é…
                if remaining_sentences > 0:
                    allocated_words = max(
                        expected_words,  # è‡³å°‘åˆ†é…æœŸæœ›çš„è¯æ•°
                        int(remaining_words / remaining_sentences)  # æˆ–è€…å¹³å‡åˆ†é…
                    )
                else:
                    allocated_words = remaining_words
                
                best_end = min(word_idx + allocated_words - 1, len(word_segments) - 1)
            
            # è¾¹ç•Œæ£€æŸ¥
            best_start = max(0, min(best_start, len(word_segments) - 1))
            best_end = max(best_start, min(best_end, len(word_segments) - 1))
            
            # è·å–è¯çº§è¯¦ç»†ä¿¡æ¯
            sentence_words = []
            for j in range(best_start, best_end + 1):
                if j < len(word_segments):
                    sentence_words.append(word_segments[j])
            
            # è·å–å¯¹åº”çš„ä¸­æ–‡
            chi_text = chi_sentences[i] if i < len(chi_sentences) else ""
            
            # è®¡ç®—æ—¶é—´
            if len(sentence_words) > 0:
                start_time = sentence_words[0]['start']
                end_time = sentence_words[-1]['end']
            else:
                start_time = 0
                end_time = 0
            
            aligned.append({
                'index': i + 1,
                'start': start_time,
                'end': end_time,
                'english': eng_sent,
                'chinese': chi_text,
                'words': sentence_words,
                'score': match_rate,
                'word_start_idx': best_start,
                'word_end_idx': best_end
            })
            
            # æ›´æ–°word_idx
            word_idx = best_end + 1
            
            if i < 5 or i >= len(eng_sentences) - 3:
                print(f"   ğŸ¯ {i+1}: {start_time:.2f}s-{end_time:.2f}s, {len(sentence_words)} è¯, åŒ¹é… {match_rate*100:.0f}%")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å‰©ä½™çš„è¯
        if word_idx < len(word_segments):
            remaining = len(word_segments) - word_idx
            print(f"   âš ï¸ è¿˜æœ‰ {remaining} ä¸ªè¯æœªä½¿ç”¨ï¼Œæ·»åŠ åˆ°æœ€åä¸€å¥")
            
            # æŠŠå‰©ä½™çš„è¯æ·»åŠ åˆ°æœ€åä¸€å¥
            if len(aligned) > 0:
                last_sentence = aligned[-1]
                for j in range(word_idx, len(word_segments)):
                    last_sentence['words'].append(word_segments[j])
                
                # æ›´æ–°ç»“æŸæ—¶é—´
                if len(last_sentence['words']) > 0:
                    last_sentence['end'] = last_sentence['words'][-1]['end']
                    last_sentence['word_end_idx'] = len(word_segments) - 1
        
        print(f"   âœ… {len(aligned)} ä¸ªå¥å­å¯¹é½å®Œæˆ")
        return aligned
    
    def create_karaoke_subtitle(self, segment: dict, next_start: float = None) -> list:
        """åˆ›å»ºå¡æ‹‰OKå­—å¹• - é€è¯é«˜äº®"""
        clips = []
        
        # è®¡ç®—ç»“æŸæ—¶é—´
        end_time = segment['end']
        if next_start is not None:
            end_time = max(end_time, min(next_start, end_time + 0.3))
        
        duration = end_time - segment['start']
        
        # åˆ›å»ºè‹±æ–‡å¡æ‹‰OKæ•ˆæœ
        eng_clip = self.create_word_highlight_clip(
            segment['english'],
            segment['words'],
            segment['start'],
            duration,
            y_pos=350,
            is_english=True
        )
        
        # åˆ›å»ºä¸­æ–‡å­—å¹•ï¼ˆå›ºå®šé¢œè‰²ï¼‰- è°ƒä½ä½ç½®é¿å…é‡å 
        chi_clip = self.create_static_subtitle(
            segment['chinese'],
            segment['start'],
            duration,
            y_pos=620
        )
        
        return [eng_clip, chi_clip]
    
    def create_word_highlight_clip(self, text: str, words: list, start_time: float, 
                                   duration: float, y_pos: int, is_english: bool):
        """åˆ›å»ºé€è¯é«˜äº®åŠ¨ç”» - å±…ä¸­å¯¹é½ + æ™ºèƒ½æ¢è¡Œ"""
        
        def make_frame(t):
            # åˆ›å»ºé€æ˜èƒŒæ™¯ - å¢åŠ é«˜åº¦æ”¯æŒ3è¡Œ
            img = Image.new('RGBA', (1920, 280), (0, 0, 0, 0))
            draw = ImageDraw.Draw(img)
            
            # åŠ è½½å­—ä½“
            font = self.get_system_font(48)
            
            # æ–‡æœ¬å·²ç»åœ¨load_storiesä¸­æ¸…ç†è¿‡å¼•å·äº†
            text_words = text.split()
            
            # æ™ºèƒ½åˆ†è¡Œ - æœ€å¤š3è¡Œï¼Œä¸æ‹†åˆ†å•è¯
            max_width = 1920 - 200  # å·¦å³å„100åƒç´ è¾¹è·
            lines = []
            current_line = []
            current_width = 0
            
            for word in text_words[:len(words)]:
                bbox = draw.textbbox((0, 0), word + " ", font=font)
                word_width = bbox[2] - bbox[0]
                
                # å¦‚æœå½“å‰è¡Œæ”¾ä¸ä¸‹ï¼Œä¸”æœªè¶…è¿‡3è¡Œï¼Œæ‰æ¢è¡Œ
                if current_width + word_width > max_width and current_line and len(lines) < 3:
                    lines.append(current_line)
                    current_line = [word]
                    current_width = word_width
                else:
                    current_line.append(word)
                    current_width += word_width
            
            if current_line:
                lines.append(current_line)
            
            # å¦‚æœè¶…è¿‡3è¡Œï¼Œæ™ºèƒ½åˆå¹¶
            if len(lines) > 3:
                all_words = [w for line in lines for w in line]
                third = len(all_words) // 3
                lines = [
                    all_words[:third],
                    all_words[third:third*2],
                    all_words[third*2:]
                ]
            
            # è®¡ç®—å½“å‰æ—¶é—´å¯¹åº”çš„è¯ç´¢å¼•
            current_time = start_time + t
            current_word_idx = -1
            
            for i, word_info in enumerate(words):
                if current_time >= word_info['start'] and current_time <= word_info['end']:
                    current_word_idx = i
                    break
                elif current_time < word_info['start']:
                    current_word_idx = max(0, i - 1)
                    break
            
            if current_word_idx == -1 and words:
                current_word_idx = len(words) - 1
            
            # ç»˜åˆ¶æ¯è¡Œæ–‡å­— - å±…ä¸­å¯¹é½
            line_height = 58
            start_y = (280 - len(lines) * line_height) // 2
            
            word_global_idx = 0
            for line_idx, line_words in enumerate(lines):
                # è®¡ç®—è¿™ä¸€è¡Œçš„æ€»å®½åº¦
                line_text = ' '.join(line_words)
                bbox = draw.textbbox((0, 0), line_text, font=font)
                line_width = bbox[2] - bbox[0]
                
                # å±…ä¸­èµ·å§‹ä½ç½®
                x_offset = (1920 - line_width) // 2
                y_pos_line = start_y + line_idx * line_height
                
                # ç»˜åˆ¶è¿™ä¸€è¡Œçš„æ¯ä¸ªè¯
                for word in line_words:
                    # æ ¹æ®æ˜¯å¦æ˜¯å½“å‰è¯é€‰æ‹©é¢œè‰² - ä½¿ç”¨å¯¹æ¯”è‰²æ–¹æ¡ˆ
                    colors = self.color_scheme
                    if word_global_idx < current_word_idx:
                        # å·²è¯» - ä½¿ç”¨ read é¢œè‰²ï¼ˆä¸å¤ªæš—ï¼Œä¿æŒå¯è¯»ï¼‰
                        color = (*colors.get('read', (180, 180, 180)), 255)
                    elif word_global_idx == current_word_idx:
                        # æ­£åœ¨è¯» - ä½¿ç”¨ highlight é«˜äº®è‰²ï¼ˆéå¸¸é†’ç›®ï¼‰
                        color = (*colors.get('highlight', (255, 255, 100)), 255)
                    else:
                        color = (255, 255, 255, 255)  # æœªè¯» - ç™½è‰²
                    
                    # æè¾¹
                    for dx in [-2, -1, 0, 1, 2]:
                        for dy in [-2, -1, 0, 1, 2]:
                            if abs(dx) + abs(dy) <= 2:
                                draw.text((x_offset + dx, y_pos_line + dy), word, 
                                        font=font, fill=(0, 0, 0, 255))
                    
                    # ä¸»æ–‡å­—
                    draw.text((x_offset, y_pos_line), word, font=font, fill=color)
                    
                    # æ›´æ–°ä½ç½®
                    bbox = draw.textbbox((0, 0), word + " ", font=font)
                    x_offset += (bbox[2] - bbox[0])
                    word_global_idx += 1
            
            return np.array(img)
        
        clip = mp.VideoClip(make_frame, duration=duration)
        return clip.with_position(('center', y_pos)).with_start(start_time)
    
    def create_static_subtitle(self, text: str, start_time: float, duration: float, y_pos: int):
        """åˆ›å»ºé™æ€å­—å¹• - å±…ä¸­å¯¹é½ + æ™ºèƒ½åˆ†è¡Œ"""
        font = self.get_system_font(44)
        
        # æ¸…ç†æ–‡æœ¬ - ç§»é™¤å¤šä½™çš„å¼•å·
        clean_text = text.replace('"', '').replace('"', '').replace('"', '').strip()
        
        # åˆ›å»ºå›¾åƒç”¨äºæµ‹é‡
        img = Image.new('RGBA', (1920, 200), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        
        # æ™ºèƒ½åˆ†è¡Œ - è€ƒè™‘å·¦å³è¾¹è·ï¼Œæ”¯æŒæœ€å¤š3è¡Œ
        max_width = 1920 - 200  # å·¦å³å„100åƒç´ è¾¹è·
        
        # æ£€æŸ¥å•è¡Œæ˜¯å¦è¶…å®½
        bbox = draw.textbbox((0, 0), clean_text, font=font)
        text_width = bbox[2] - bbox[0]
        
        if text_width <= max_width:
            lines = [clean_text]
        else:
            # éœ€è¦åˆ†è¡Œ - åœ¨æ ‡ç‚¹å¤„ä¼˜å…ˆåˆ†å‰²
            # å°è¯•åˆ†æˆ2è¡Œ
            if len(clean_text) <= 40:
                mid = len(clean_text) // 2
                best_split = mid
                
                # åœ¨ä¸­é—´é™„è¿‘æ‰¾æ ‡ç‚¹ç¬¦å·
                for i in range(mid - 8, mid + 9):
                    if i > 0 and i < len(clean_text) and clean_text[i] in 'ï¼Œã€‚ï¼ï¼Ÿã€ï¼›':
                        best_split = i + 1
                        break
                
                line1 = clean_text[:best_split].strip()
                line2 = clean_text[best_split:].strip()
                
                # æ£€æŸ¥ç¬¬äºŒè¡Œæ˜¯å¦è¿˜è¶…å®½
                bbox2 = draw.textbbox((0, 0), line2, font=font)
                if bbox2[2] - bbox2[0] <= max_width:
                    lines = [line1, line2]
                else:
                    # éœ€è¦3è¡Œ
                    third = len(clean_text) // 3
                    split1 = third
                    split2 = third * 2
                    
                    # åœ¨åˆ†å‰²ç‚¹é™„è¿‘æ‰¾æ ‡ç‚¹
                    for i in range(split1 - 5, split1 + 6):
                        if i > 0 and i < len(clean_text) and clean_text[i] in 'ï¼Œã€‚ï¼ï¼Ÿã€ï¼›':
                            split1 = i + 1
                            break
                    
                    for i in range(split2 - 5, split2 + 6):
                        if i > split1 and i < len(clean_text) and clean_text[i] in 'ï¼Œã€‚ï¼ï¼Ÿã€ï¼›':
                            split2 = i + 1
                            break
                    
                    lines = [
                        clean_text[:split1].strip(),
                        clean_text[split1:split2].strip(),
                        clean_text[split2:].strip()
                    ]
            else:
                # é•¿æ–‡æœ¬ç›´æ¥åˆ†3è¡Œ
                third = len(clean_text) // 3
                lines = [
                    clean_text[:third].strip(),
                    clean_text[third:third*2].strip(),
                    clean_text[third*2:].strip()
                ]
        
        # ç»˜åˆ¶å­—å¹• - å±…ä¸­å¯¹é½
        line_height = 55
        start_y = (200 - len(lines) * line_height) // 2
        
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            line_width = bbox[2] - bbox[0]
            
            # å±…ä¸­ä½ç½®
            x = (1920 - line_width) // 2
            y = start_y + i * line_height
            
            # æè¾¹
            for dx in [-2, -1, 0, 1, 2]:
                for dy in [-2, -1, 0, 1, 2]:
                    if abs(dx) + abs(dy) <= 2:
                        draw.text((x + dx, y + dy), line, font=font, fill=(0, 0, 0, 255))
            
            # ä¸»æ–‡å­— - ä½¿ç”¨ subtitle å¯¹æ¯”è‰²ï¼ˆå’Œä¸»é¢˜è‰²å½¢æˆåå·®ï¼‰
            subtitle_color = self.color_scheme.get('subtitle', (255, 215, 100))
            draw.text((x, y), line, font=font, fill=(*subtitle_color, 255))
        
        img_clip = mp.ImageClip(np.array(img), duration=duration)
        return img_clip.with_position(('center', y_pos)).with_start(start_time)
    
    def get_color_scheme(self, story_num: int) -> dict:
        """è·å–é¢œè‰²æ–¹æ¡ˆ - æ¯ä¸ªä¸»é¢˜æœ‰ç‹¬ç‰¹çš„é…è‰²å’ŒèƒŒæ™¯é£æ ¼
        
        è®¾è®¡åŸåˆ™ï¼š
        1. highlightï¼ˆé«˜äº®ï¼‰- è¦éå¸¸äº®ã€é†’ç›®ï¼Œç”¨äºå½“å‰æœ—è¯»çš„è¯
        2. subtitleï¼ˆå­—å¹•ï¼‰- ç”¨é‡‘é»„è‰²ï¼Œæœ€é†’ç›®æœ€å¥½çœ‹
        3. readï¼ˆå·²è¯»ï¼‰- ç¨æš—ä½†ä¸è¦å¤ªæš—ï¼Œä¿æŒå¯è¯»æ€§
        4. primaryï¼ˆä¸»è‰²ï¼‰- ç”¨äºé¢‘è°±æ¡ç­‰è£…é¥°
        """
        import random
        random.seed(story_num)
        
        # å®šä¹‰ä¸°å¯Œçš„ä¸»é¢˜é…è‰²æ–¹æ¡ˆ - å¼ºè°ƒå¯¹æ¯”åº¦å’Œé†’ç›®åº¦
        schemes = [
            {
                'name': 'å†°è“æå…‰',
                'primary': (100, 200, 255),      # ä¸»è‰² - å†°è“ï¼ˆé¢‘è°±ï¼‰
                'highlight': (255, 255, 0),      # é«˜äº®è‰² - äº®é»„ï¼ˆæœ€é†’ç›®ï¼‰
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (150, 200, 220),         # å·²è¯» - æ·¡è“
                'bg_style': 'aurora',
                'bg_colors': [(10, 20, 50), (20, 40, 80), (30, 60, 100)],
                'star_color': (180, 220, 255),
                'r_base': 50, 'r_range': 205, 'g_base': 100, 'g_range': 155, 'b_base': 255, 'b_range': 0
            },
            {
                'name': 'æ¢¦å¹»ç´«ç½—å…°',
                'primary': (180, 100, 255),      # ä¸»è‰² - ç´«ç½—å…°
                'highlight': (255, 255, 0),      # é«˜äº®è‰² - äº®é»„
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (200, 180, 220),         # å·²è¯» - æ·¡ç´«
                'bg_style': 'fantasy',
                'bg_colors': [(30, 10, 50), (50, 20, 80), (40, 15, 60)],
                'star_color': (200, 180, 255),
                'r_base': 138, 'r_range': 117, 'g_base': 43, 'g_range': 170, 'b_base': 226, 'b_range': 30
            },
            {
                'name': 'ç¿¡ç¿ æå…‰',
                'primary': (80, 255, 180),       # ä¸»è‰² - ç¿¡ç¿ ç»¿
                'highlight': (255, 255, 0),      # é«˜äº®è‰² - äº®é»„
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (180, 220, 200),         # å·²è¯» - æ·¡ç»¿
                'bg_style': 'aurora',
                'bg_colors': [(5, 25, 20), (10, 40, 35), (15, 50, 40)],
                'star_color': (180, 255, 220),
                'r_base': 46, 'r_range': 134, 'g_base': 213, 'g_range': 42, 'b_base': 152, 'b_range': 103
            },
            {
                'name': 'çƒˆç„°çº¢',
                'primary': (255, 80, 80),        # ä¸»è‰² - é²œçº¢ï¼ˆé«˜äº®çº¢ï¼‰
                'highlight': (255, 255, 0),      # é«˜äº®è‰² - äº®é»„ï¼ˆæœ€é†’ç›®ï¼‰
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (255, 180, 180),         # å·²è¯» - æ·¡çº¢
                'bg_style': 'fire',              # èƒŒæ™¯é£æ ¼ - ç«ç„°
                'bg_colors': [(40, 10, 10), (60, 15, 15), (50, 12, 12)],
                'star_color': (255, 200, 150),
                'r_base': 255, 'r_range': 0, 'g_base': 50, 'g_range': 150, 'b_base': 50, 'b_range': 100
            },
            {
                'name': 'é‡‘è‰²æš–é˜³',
                'primary': (255, 200, 100),      # ä¸»è‰² - é‡‘è‰²
                'highlight': (255, 255, 255),    # é«˜äº®è‰² - çº¯ç™½ï¼ˆæœ€é†’ç›®ï¼‰
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (230, 210, 180),         # å·²è¯» - æ·¡é‡‘
                'bg_style': 'sunset',
                'bg_colors': [(40, 20, 10), (60, 30, 15), (50, 25, 12)],
                'star_color': (255, 220, 180),
                'r_base': 255, 'r_range': 0, 'g_base': 140, 'g_range': 115, 'b_base': 0, 'b_range': 100
            },
            {
                'name': 'è–°è¡£è‰æ¢¦',
                'primary': (200, 150, 255),      # ä¸»è‰² - è–°è¡£è‰
                'highlight': (255, 255, 0),      # é«˜äº®è‰² - äº®é»„
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (210, 200, 230),         # å·²è¯» - æ·¡ç´«
                'bg_style': 'fantasy',
                'bg_colors': [(25, 20, 40), (40, 35, 60), (35, 30, 50)],
                'star_color': (220, 200, 255),
                'r_base': 200, 'r_range': 55, 'g_base': 150, 'g_range': 80, 'b_base': 255, 'b_range': 0
            },
            {
                'name': 'æµ·æ´‹æ·±è“',
                'primary': (80, 150, 255),       # ä¸»è‰² - æ·±è“
                'highlight': (255, 255, 0),      # é«˜äº®è‰² - äº®é»„
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (160, 190, 230),         # å·²è¯» - æ·¡è“
                'bg_style': 'ocean',
                'bg_colors': [(5, 15, 35), (10, 25, 50), (8, 20, 40)],
                'star_color': (150, 200, 255),
                'r_base': 50, 'r_range': 150, 'g_base': 100, 'g_range': 100, 'b_base': 255, 'b_range': 0
            },
            {
                'name': 'æ£®æ—ç»¿æ„',
                'primary': (100, 220, 120),      # ä¸»è‰² - æ£®æ—ç»¿
                'highlight': (255, 255, 0),      # é«˜äº®è‰² - äº®é»„
                'subtitle': (255, 215, 0),       # ä¸­æ–‡å­—å¹• - é‡‘é»„è‰²
                'read': (180, 210, 180),         # å·²è¯» - æ·¡ç»¿
                'bg_style': 'forest',
                'bg_colors': [(10, 25, 15), (15, 35, 20), (12, 30, 18)],
                'star_color': (180, 230, 190),
                'r_base': 80, 'r_range': 100, 'g_base': 180, 'g_range': 50, 'b_base': 100, 'b_range': 80
            },
        ]
        
        # ç¬¬ä¸€ä¸ªæ•…äº‹å›ºå®šç”¨å†°è“æå…‰
        if story_num == 1:
            return schemes[0]
        else:
            return schemes[(story_num - 1) % len(schemes)]
    
    def create_background(self) -> str:
        """åˆ›å»ºä¸»é¢˜èƒŒæ™¯ - æ ¹æ®é…è‰²æ–¹æ¡ˆç”Ÿæˆç‹¬ç‰¹èƒŒæ™¯ï¼ˆä¸“ä¸šå»è‰²å¸¦ç‰ˆæœ¬ï¼‰"""
        import random
        
        colors = self.color_scheme
        bg_style = colors.get('bg_style', 'aurora')
        bg_colors = colors.get('bg_colors', [(10, 20, 50), (20, 40, 80), (30, 60, 100)])
        star_color = colors.get('star_color', (200, 200, 255))
        
        # ä½¿ç”¨numpyåˆ›å»ºè¶…å¹³æ»‘æ¸å˜ï¼ˆä¸“ä¸šå»è‰²å¸¦ï¼‰
        width, height = 1920, 1080
        
        # æ ¹æ®é£æ ¼åˆ›å»ºä¸åŒçš„èƒŒæ™¯
        if bg_style == 'aurora':
            # æå…‰æ•ˆæœ - ç®€æ´æ¸å˜
            color_start = np.array(bg_colors[0], dtype=np.float64)
            color_end = np.array(bg_colors[1], dtype=np.float64)
            
        elif bg_style == 'fantasy':
            # å¹»å¢ƒæ•ˆæœ - æŸ”å’Œçš„ç´«è‰²/ç²‰è‰²æ¸å˜
            color_start = np.array(bg_colors[0], dtype=np.float64)
            color_end = np.array([
                bg_colors[1][0] * 0.8,
                bg_colors[1][1] * 0.8,
                bg_colors[1][2] * 0.8
            ], dtype=np.float64)
            
        elif bg_style == 'romantic':
            # æµªæ¼«ç²‰è‰²å¤©ç©º
            color_start = np.array(bg_colors[0], dtype=np.float64)
            color_end = np.array([
                bg_colors[0][0] + (bg_colors[1][0] - bg_colors[0][0]) * 0.5,
                bg_colors[0][1] + (bg_colors[1][1] - bg_colors[0][1]) * 0.5,
                bg_colors[0][2] + (bg_colors[1][2] - bg_colors[0][2]) * 0.5
            ], dtype=np.float64)
            
        elif bg_style == 'fire':
            # ç«ç„°æ•ˆæœ - æ·±çº¢æ¸å˜
            color_start = np.array(bg_colors[0], dtype=np.float64)
            color_end = np.array([
                bg_colors[1][0],
                bg_colors[1][1] * 0.5,
                bg_colors[1][2] * 0.3
            ], dtype=np.float64)
            
        elif bg_style == 'sunset':
            # æ—¥è½æ•ˆæœ
            color_start = np.array(bg_colors[0], dtype=np.float64)
            color_end = np.array([
                bg_colors[1][0],
                bg_colors[1][1] * 0.7,
                bg_colors[1][2] * 0.5
            ], dtype=np.float64)
            
        else:  # ocean, forest ç­‰
            # é»˜è®¤æ¸å˜
            color_start = np.array(bg_colors[0], dtype=np.float64)
            color_end = np.array(bg_colors[1], dtype=np.float64)
        
        # åˆ›å»ºé«˜ç²¾åº¦æ¸å˜æ•°ç»„
        gradient = np.zeros((height, width, 3), dtype=np.float64)
        
        # ä½¿ç”¨è¶…å¹³æ»‘çš„æ¸å˜å‡½æ•°ï¼ˆsmootherstepï¼‰
        for y in range(height):
            ratio = y / height
            # smootherstep: 6t^5 - 15t^4 + 10t^3
            smooth_ratio = ratio * ratio * ratio * (ratio * (ratio * 6 - 15) + 10)
            color = color_start * (1 - smooth_ratio) + color_end * smooth_ratio
            gradient[y, :] = color
        
        # æ·»åŠ BayerçŸ©é˜µæŠ–åŠ¨ï¼ˆä¸“ä¸šå»è‰²å¸¦æŠ€æœ¯ï¼‰
        bayer_matrix = np.array([
            [ 0, 32,  8, 40,  2, 34, 10, 42],
            [48, 16, 56, 24, 50, 18, 58, 26],
            [12, 44,  4, 36, 14, 46,  6, 38],
            [60, 28, 52, 20, 62, 30, 54, 22],
            [ 3, 35, 11, 43,  1, 33,  9, 41],
            [51, 19, 59, 27, 49, 17, 57, 25],
            [15, 47,  7, 39, 13, 45,  5, 37],
            [63, 31, 55, 23, 61, 29, 53, 21]
        ], dtype=np.float64) / 64.0 - 0.5
        
        # åˆ›å»ºå…¨å°ºå¯¸çš„æŠ–åŠ¨çŸ©é˜µ
        tile_h = height // 8 + 1
        tile_w = width // 8 + 1
        dither = np.tile(bayer_matrix, (tile_h, tile_w))[:height, :width]
        dither = dither[:, :, np.newaxis]
        dither = np.repeat(dither, 3, axis=2)
        
        # åº”ç”¨æŠ–åŠ¨
        gradient_dithered = gradient + dither * 4.0
        
        # è½¬æ¢ä¸ºuint8
        gradient_uint8 = np.clip(gradient_dithered, 0, 255).astype(np.uint8)
        
        # éå¸¸è½»å¾®çš„é«˜æ–¯æ¨¡ç³Š
        gradient_final = cv2.GaussianBlur(gradient_uint8, (3, 3), 0.3)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        img = Image.fromarray(gradient_final, mode='RGB')
        draw = ImageDraw.Draw(img)
        
        # æ·»åŠ ä¸»é¢˜è‰²æ˜Ÿå…‰ç²’å­
        random.seed(42)
        num_stars = 100
        
        for _ in range(num_stars):
            x = random.randint(0, 1920)
            y = random.randint(0, 800)
            size = random.choice([1, 1, 1, 2, 2, 3])
            brightness = random.uniform(0.6, 1.0)
            
            # ä½¿ç”¨ä¸»é¢˜æ˜Ÿæ˜Ÿé¢œè‰²
            sr = int(star_color[0] * brightness)
            sg = int(star_color[1] * brightness)
            sb = int(star_color[2] * brightness)
            
            if size == 1:
                draw.point((x, y), fill=(sr, sg, sb))
            elif size == 2:
                # åå­—æ˜Ÿ
                for dx, dy in [(0, 0), (1, 0), (-1, 0), (0, 1), (0, -1)]:
                    if 0 <= x + dx < 1920 and 0 <= y + dy < 1080:
                        draw.point((x + dx, y + dy), fill=(sr, sg, sb))
            else:
                # å¤§æ˜Ÿæ˜Ÿ
                for dx in range(-2, 3):
                    for dy in range(-2, 3):
                        if abs(dx) + abs(dy) <= 2:
                            fade = 1 - (abs(dx) + abs(dy)) * 0.2
                            if 0 <= x + dx < 1920 and 0 <= y + dy < 1080:
                                draw.point((x + dx, y + dy), fill=(
                                    int(sr * fade), int(sg * fade), int(sb * fade)
                                ))
        
        bg_path = self.temp_dir / "karaoke_bg.png"
        img.save(bg_path)
        return str(bg_path)
    
    def create_visualizer(self, audio_path: str, bg_path: str, duration: float):
        """åˆ›å»ºéŸ³é¢‘å¯è§†åŒ– + åŠ¨æ€æ˜Ÿå…‰"""
        y, sr = librosa.load(audio_path)
        stft = librosa.stft(y, hop_length=256, n_fft=1024)
        magnitude = np.abs(stft)
        db = librosa.amplitude_to_db(magnitude, ref=np.max)
        times = librosa.times_like(stft, sr=sr, hop_length=256)
        freqs = librosa.fft_frequencies(sr=sr, n_fft=1024)
        
        freq_mask = (freqs >= 80) & (freqs <= 4000)
        db_filtered = db[freq_mask]
        
        n_bars = 45
        db_bars = np.zeros((n_bars, db.shape[1]))
        for i in range(n_bars):
            start = i * len(db_filtered) // n_bars
            end = (i + 1) * len(db_filtered) // n_bars
            db_bars[i] = np.mean(db_filtered[start:end], axis=0)
        
        # ç”ŸæˆåŠ¨æ€æ˜Ÿæ˜Ÿï¼ˆä¼šé—ªçƒï¼‰
        import random
        random.seed(123)
        stars = []
        for _ in range(60):  # 60ä¸ªåŠ¨æ€æ˜Ÿæ˜Ÿ
            stars.append({
                'x': random.randint(0, 1920),
                'y': random.randint(0, 700),
                'speed': random.uniform(0.5, 2.0),  # é—ªçƒé€Ÿåº¦
                'phase': random.uniform(0, 6.28),  # åˆå§‹ç›¸ä½
                'size': random.choice([1, 2, 3])
            })
        
        # è·å–é¢œè‰²æ–¹æ¡ˆ
        colors = self.color_scheme
        star_color = colors.get('star_color', (200, 200, 255))
        
        def make_frame(t):
            bg = cv2.imread(bg_path)
            bg = cv2.resize(bg, (1920, 1080))
            
            # ç»˜åˆ¶åŠ¨æ€æ˜Ÿå…‰ - ä½¿ç”¨ä¸»é¢˜æ˜Ÿæ˜Ÿé¢œè‰²
            for star in stars:
                brightness = 0.5 + 0.5 * np.sin(star['speed'] * t + star['phase'])
                brightness = max(0.4, min(1.0, brightness))
                
                x, y = int(star['x']), int(star['y'])
                size = star['size']
                
                # ä½¿ç”¨ä¸»é¢˜æ˜Ÿæ˜Ÿé¢œè‰²
                sr = int(star_color[0] * brightness)
                sg = int(star_color[1] * brightness)
                sb = int(star_color[2] * brightness)
                
                if size == 1:
                    if 0 <= x < 1920 and 0 <= y < 1080:
                        bg[y, x] = [sb, sg, sr]  # BGRæ ¼å¼
                elif size == 2:
                    for dx, dy in [(0,0), (1,0), (-1,0), (0,1), (0,-1)]:
                        nx, ny = x + dx, y + dy
                        if 0 <= nx < 1920 and 0 <= ny < 1080:
                            bg[ny, nx] = [sb, sg, sr]
                else:
                    for dx in range(-2, 3):
                        for dy in range(-2, 3):
                            if abs(dx) + abs(dy) <= 2:
                                nx, ny = x + dx, y + dy
                                if 0 <= nx < 1920 and 0 <= ny < 1080:
                                    fade = 1 - (abs(dx) + abs(dy)) * 0.15
                                    bg[ny, nx] = [int(sb * fade), int(sg * fade), int(sr * fade)]
            
            idx = np.argmin(np.abs(times - t))
            spectrum = np.clip((db_bars[:, idx] + 60) / 60, 0, 1)
            
            # ç»˜åˆ¶é¢‘è°± - ä½¿ç”¨é…è‰²æ–¹æ¡ˆ
            h, w = bg.shape[:2]
            bar_w = 18
            spacing = 4
            total_w = n_bars * (bar_w + spacing)
            start_x = (w - total_w) // 2
            
            for i, amp in enumerate(spectrum):
                x = start_x + i * (bar_w + spacing)
                bar_h = int(amp * 220)
                bar_h = max(3, bar_h)
                
                for h_offset in range(bar_h):
                    ratio = h_offset / max(bar_h, 1)
                    r = int(colors['r_base'] + ratio * colors['r_range'])
                    g = int(colors['g_base'] + ratio * colors['g_range'])
                    b = int(colors['b_base'] + ratio * colors['b_range'])
                    
                    y_pos = h - 100 - h_offset
                    cv2.rectangle(bg, (x, y_pos), (x + bar_w, y_pos + 1), (b, g, r), -1)
            
            # è¿›åº¦æ¡ - ä½¿ç”¨é…è‰²æ–¹æ¡ˆ
            bar_y = h - 45
            bar_start = 150
            bar_end = w - 150
            bar_width = bar_end - bar_start
            
            cv2.rectangle(bg, (bar_start, bar_y - 3), (bar_end, bar_y + 3), (30, 30, 40), -1)
            
            progress = t / duration
            prog_x = int(bar_start + bar_width * progress)
            
            for x in range(bar_start, prog_x, 3):
                ratio = (x - bar_start) / bar_width
                r = int(colors['r_base'] + ratio * colors['r_range'])
                g = int(colors['g_base'] + ratio * colors['g_range'])
                b = int(colors['b_base'] + ratio * colors['b_range'])
                cv2.rectangle(bg, (x, bar_y - 3), (x + 3, bar_y + 3), (b, g, r), -1)
            
            cv2.circle(bg, (prog_x, bar_y), 7, (255, 255, 255), -1)
            cv2.circle(bg, (prog_x, bar_y), 9, (255, 220, 100), 2)
            
            return cv2.cvtColor(bg, cv2.COLOR_BGR2RGB)
        
        return mp.VideoClip(make_frame, duration=duration)
    
    def generate(self, story_num: int = 1, use_forced_alignment: bool = True):
        """ç”Ÿæˆå¡æ‹‰OKè§†é¢‘ - ä½¿ç”¨ Forced Alignment ç²¾ç¡®å¯¹é½
        
        Args:
            story_num: æ•…äº‹ç¼–å·
            use_forced_alignment: æ˜¯å¦ä½¿ç”¨ WhisperX Forced Alignmentï¼ˆæ¨èTrueï¼‰
        """
        # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ
        self.color_scheme = self.get_color_scheme(story_num)
        
        print(f"\n{'='*60}")
        print(f"ğŸ¤ ç”Ÿæˆæ•…äº‹ {story_num} - å¡æ‹‰OKé«˜äº®ç‰ˆæœ¬")
        print(f"{'='*60}\n")
        
        print("ç‰¹ç‚¹:")
        print("  ğŸ¤ è¯çº§æ—¶é—´æˆ³ - æœ€ç²¾ç¡®")
        print("  ğŸŒˆ é€è¯é«˜äº® - å¡æ‹‰OKæ•ˆæœ")
        print("  ğŸ¯ Forced Alignment - è§£å†³æ•°å­—/ç¼©å†™è¯†åˆ«é—®é¢˜" if use_forced_alignment else "  ğŸ¯ æ–‡æœ¬å¯¹é½ - ä¸­è‹±æ–‡1:1å¯¹åº”")
        print("  âœ… çœŸå®ä¸­æ–‡ - Chinese_Storiesç›®å½•")
        print(f"  ğŸ¨ é…è‰²æ–¹æ¡ˆ - {self.color_scheme['name']}")
        print("  â­ æ˜Ÿå…‰ç‰¹æ•ˆ - åŠ¨æ€ç²’å­")
        print()
        
        # åŠ è½½éŸ³é¢‘
        audio_files = sorted(list(self.audio_dir.glob("*.wav")))
        audio_path = str(audio_files[story_num - 1])
        
        # åŠ è½½åŸæ–‡ï¼ˆè‹±æ–‡å’Œä¸­æ–‡ï¼‰
        eng_sentences, chi_sentences = self.load_stories(story_num)
        
        # è·å–å®Œæ•´è‹±æ–‡æ–‡æœ¬ï¼ˆç”¨äº Forced Alignmentï¼‰
        full_english_text = ' '.join(eng_sentences)
        
        if use_forced_alignment:
            # ä½¿ç”¨ WhisperX Forced Alignment æå–ç²¾ç¡®æ—¶é—´æˆ³
            word_timestamps = self.extract_word_timestamps_with_forced_alignment(audio_path, full_english_text)
            # ä½¿ç”¨æ–°çš„å¯¹é½æ–¹æ³•
            aligned = self.align_sentences_with_forced_alignment(word_timestamps, eng_sentences, chi_sentences)
        else:
            # ä½¿ç”¨æ—§æ–¹æ³•ï¼ˆä¿ç•™å…¼å®¹ï¼‰
            word_timestamps = self.extract_word_timestamps(audio_path)
            aligned = self.align_sentences(word_timestamps, eng_sentences, chi_sentences)
        
        # åˆ›å»ºå­—å¹•
        print("\nğŸ¬ åˆ›å»ºå¡æ‹‰OKå­—å¹•...")
        subtitle_clips = []
        for i, segment in enumerate(aligned):
            next_start = aligned[i + 1]['start'] if i + 1 < len(aligned) else None
            clips = self.create_karaoke_subtitle(segment, next_start)
            subtitle_clips.extend(clips)
            if i < 3:
                print(f"   ğŸ¤ å¥å­ {i+1}: {segment['start']:.2f}s-{segment['end']:.2f}s")
        
        if len(aligned) > 3:
            print(f"   ... è¿˜æœ‰ {len(aligned) - 3} ä¸ª")
        
        print(f"   âœ… {len(subtitle_clips)} ä¸ªå­—å¹•ç‰‡æ®µ")
        
        # åˆ›å»ºå¯è§†åŒ–
        print("\nğŸµ åˆ›å»ºå¯è§†åŒ–...")
        bg_path = self.create_background()
        
        # ä½¿ç”¨librosaè·å–æ—¶é•¿
        import librosa
        y, sr = librosa.load(audio_path, sr=None)
        duration = len(y) / sr
        
        visualizer = self.create_visualizer(audio_path, bg_path, duration)
        
        # åˆæˆ
        print("\nğŸ¬ åˆæˆæœ€ç»ˆè§†é¢‘...")
        final = mp.CompositeVideoClip([visualizer] + subtitle_clips)
        final = final.with_audio(mp.AudioFileClip(audio_path))
        
        output_path = self.output_dir / f"Story_{story_num:02d}_Karaoke_Complete.mp4"
        
        print(f"\nâš¡ ä½¿ç”¨æ— æŸç¼–ç ï¼ˆå®Œå…¨æ— è‰²å¸¦ï¼Œæ–‡ä»¶è¾ƒå¤§ï¼‰...")
        final.write_videofile(
            str(output_path),
            fps=30,
            codec='libx264',
            audio_codec='aac',
            preset='veryslow',
            threads=8,
            ffmpeg_params=[
                '-crf', '0',  # CRF 0 = å®Œå…¨æ— æŸ
                '-pix_fmt', 'yuv444p',  # 4:4:4è‰²åº¦é‡‡æ ·ï¼Œæ— è‰²åº¦å‹ç¼©
                '-qp', '0',  # é‡åŒ–å‚æ•°0 = æ— æŸ
                '-movflags', '+faststart'
            ]
        )
        
        final.close()
        
        size = os.path.getsize(output_path) / (1024 * 1024)
        
        print(f"\n{'='*60}")
        print("âœ… å¡æ‹‰OKè§†é¢‘ç”ŸæˆæˆåŠŸ!")
        print(f"{'='*60}")
        print(f"ğŸ“¹ æ–‡ä»¶: {output_path}")
        print(f"ğŸ“Š å¤§å°: {size:.1f} MB")
        print(f"â±ï¸ æ—¶é•¿: {duration:.1f}ç§’")
        print(f"ğŸ¤ ç‰¹ç‚¹: é€è¯é«˜äº® + çœŸå®ä¸­æ–‡")
        
        return str(output_path)


def main():
    import sys
    
    print("="*60)
    print("ğŸ¤ å¡æ‹‰OKå¯¹é½å­—å¹•ç”Ÿæˆç³»ç»Ÿ")
    print("="*60)
    print()
    print("æ–°åŠŸèƒ½:")
    print("  ğŸŒˆ é€è¯é«˜äº® - å¡æ‹‰OKè·Ÿè¸ªæ•ˆæœ")
    print("  ğŸ¯ è¶…é«˜ç²¾åº¦ - æ”¹è¿›å¯¹é½ç®—æ³•")
    print("  âœ… çœŸå®ä¸­æ–‡ - ä½¿ç”¨Chinese_Stories")
    print("  ğŸµ ä¸“ä¸šå¯è§†åŒ– - 45ä¸ªé¢‘è°±æ¡")
    print()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == "all":
            # æ‰¹é‡ç”Ÿæˆæ‰€æœ‰æ•…äº‹
            print("ğŸ“¦ æ‰¹é‡ç”Ÿæˆæ¨¡å¼ - ç”Ÿæˆæ‰€æœ‰æ•…äº‹è§†é¢‘")
            print()
            
            generator = KaraokeAlignmentGenerator()
            audio_dir = Path("Stiries_audio")
            audio_files = sorted(list(audio_dir.glob("*.wav")))
            total = len(audio_files)
            
            print(f"ğŸ“Š å‘ç° {total} ä¸ªéŸ³é¢‘æ–‡ä»¶")
            print(f"â° é¢„è®¡æ€»æ—¶é•¿: {total * 8:.0f} åˆ†é’Ÿ")
            print()
            
            success_count = 0
            failed = []
            
            for i in range(1, total + 1):
                try:
                    print(f"\n{'='*60}")
                    print(f"ğŸ¬ [{i}/{total}] æ­£åœ¨ç”Ÿæˆæ•…äº‹ {i}")
                    print(f"{'='*60}")
                    
                    video_path = generator.generate(story_num=i)
                    
                    if video_path:
                        success_count += 1
                        print(f"âœ… æ•…äº‹ {i} å®Œæˆ ({success_count}/{total})")
                    else:
                        failed.append(i)
                        print(f"âŒ æ•…äº‹ {i} å¤±è´¥")
                        
                except Exception as e:
                    failed.append(i)
                    print(f"âŒ æ•…äº‹ {i} å‘ç”Ÿé”™è¯¯: {str(e)}")
                    continue
            
            # æ±‡æ€»æŠ¥å‘Š
            print(f"\n{'='*60}")
            print("ğŸ“Š æ‰¹é‡ç”Ÿæˆå®ŒæˆæŠ¥å‘Š")
            print(f"{'='*60}")
            print(f"âœ… æˆåŠŸ: {success_count}/{total}")
            if failed:
                print(f"âŒ å¤±è´¥: {len(failed)} ä¸ª - {failed}")
            print(f"ğŸ’¾ è¾“å‡ºç›®å½•: karaoke_alignment_videos/")
            print()
            
        else:
            # ç”ŸæˆæŒ‡å®šç¼–å·çš„æ•…äº‹
            try:
                story_num = int(sys.argv[1])
                generator = KaraokeAlignmentGenerator()
                video_path = generator.generate(story_num=story_num)
                
                if video_path:
                    print(f"\nğŸ¬ æ­£åœ¨æ‰“å¼€è§†é¢‘...")
                    try:
                        os.startfile(video_path)
                    except:
                        print(f"è¯·æ‰‹åŠ¨æ‰“å¼€: {video_path}")
                    
                    print("\nğŸ‰ å¡æ‹‰OKè§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                    print("ğŸ’¡ é€è¯é«˜äº® + çœŸå®ä¸­æ–‡ + è¶…ç²¾ç¡®å¯¹é½ï¼")
            except ValueError:
                print("âŒ é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„æ•…äº‹ç¼–å·")
                print("ç”¨æ³•: python karaoke_alignment_generator.py [ç¼–å·|all]")
    else:
        # é»˜è®¤ç”Ÿæˆç¬¬1ä¸ªæ•…äº‹
        generator = KaraokeAlignmentGenerator()
        video_path = generator.generate(story_num=1)
        
        if video_path:
            print(f"\nğŸ¬ æ­£åœ¨æ‰“å¼€è§†é¢‘...")
            try:
                os.startfile(video_path)
            except:
                print(f"è¯·æ‰‹åŠ¨æ‰“å¼€: {video_path}")
            
            print("\nğŸ‰ å¡æ‹‰OKè§†é¢‘ç”Ÿæˆå®Œæˆï¼")
            print("ğŸ’¡ é€è¯é«˜äº® + çœŸå®ä¸­æ–‡ + è¶…ç²¾ç¡®å¯¹é½ï¼")


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
å¡æ‹‰OKå¯¹é½å­—å¹•ç”Ÿæˆå™¨ - æ‰‹æœºç«–å±ç‰ˆ V3 (ç®€çº¦é£æ ¼)
ä¸“ä¸ºå¿«æ‰‹/æŠ–éŸ³è®¾è®¡ - å·¦ä¾§å¸ƒå±€ï¼Œé¿å¼€å³ä¾§åŠŸèƒ½æŒ‰é’®
- ç«–å±å°ºå¯¸: 1080x1920
- ç®€çº¦é£æ ¼ï¼šå·¦ä¸­é«˜å…‰ï¼Œå‘ä¸Šæ»šåŠ¨
- å›ºå®šé«˜å…‰ä½ç½®ï¼Œå­—å¹•æµåŠ¨
"""

import os
import numpy as np
from pathlib import Path
import librosa
import re
import moviepy as mp
from PIL import Image, ImageDraw, ImageFont
import cv2
from difflib import SequenceMatcher

# PyTorch for forced alignment
import torch
import torchaudio


class KaraokeAlignmentGeneratorMobileV3Simple:
    """å¡æ‹‰OKå¯¹é½å­—å¹•ç”Ÿæˆå™¨ - æ‰‹æœºç«–å±ç‰ˆ V3 (ç®€çº¦é£æ ¼)"""
    
    def __init__(self):
        self.output_dir = Path("karaoke_alignment_videos_mobile")
        self.output_dir.mkdir(exist_ok=True)
        
        self.temp_dir = Path("temp_karaoke_alignment_mobile")
        self.temp_dir.mkdir(exist_ok=True)
        
        self.audio_dir = Path("Stories_audio")
        self.english_dir = Path("English_Stories")
        self.chinese_dir = Path("Chinese_Stories")
        
        # ç«–å±è§†é¢‘å°ºå¯¸ (9:16)
        self.width = 1080
        self.height = 1920
        
        # å·¦ä¾§å¸ƒå±€ - é¿å¼€å³ä¾§æŒ‰é’®
        self.left_margin = 60  # å·¦è¾¹è·
        self.right_safe_zone = 200  # å³ä¾§å®‰å…¨åŒºï¼ˆé¿å¼€æŒ‰é’®ï¼‰
        self.text_width = self.width - self.left_margin - self.right_safe_zone  # å¯ç”¨æ–‡æœ¬å®½åº¦
        
        # é«˜å…‰å›ºå®šä½ç½®ï¼ˆå·¦ä¸­ï¼‰
        self.highlight_y = 960  # å±å¹•ä¸­å¿ƒé«˜åº¦
        
        # å¥å­é—´è·ï¼ˆå¢å¤§é—´è·ï¼Œé¿å…é‡å ï¼‰
        self.line_spacing = 200  # æ¯ä¸ªå¥å­å¯¹çš„é—´è·ï¼ˆè‹±æ–‡+ä¸­æ–‡+é—´éš”ï¼‰
        
        # è®¾å¤‡é…ç½®
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print("ğŸ“± å¡æ‹‰OKå¯¹é½å­—å¹•ç”Ÿæˆå™¨ - æ‰‹æœºç«–å±ç‰ˆ V3 (ç®€çº¦é£æ ¼)")
        print(f"   è§†é¢‘å°ºå¯¸: {self.width}x{self.height} (9:16)")
        print(f"   å¸ƒå±€: å·¦ä¾§å¸ƒå±€ï¼Œé¿å¼€å³ä¾§æŒ‰é’®")
        print(f"   é£æ ¼: ç®€çº¦é£æ ¼ï¼Œå‘ä¸Šæ»šåŠ¨")
        print(f"   è®¾å¤‡: {self.device}")


    
    def extract_word_timestamps_with_forced_alignment(self, audio_path: str, english_text: str) -> list:
        """ä½¿ç”¨ torchaudio Forced Alignment æå–ç²¾ç¡®è¯çº§æ—¶é—´æˆ³"""
        print("ğŸ¤ ä½¿ç”¨ torchaudio Forced Alignment æå–è¯çº§æ—¶é—´æˆ³...")
        
        bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H
        model = bundle.get_model().to(self.device)
        labels = bundle.get_labels()
        dictionary = {c.lower(): i for i, c in enumerate(labels)}
        
        import soundfile as sf
        audio_data, sample_rate = sf.read(audio_path)
        waveform = torch.tensor(audio_data).float()
        if len(waveform.shape) == 1:
            waveform = waveform.unsqueeze(0)
        elif waveform.shape[1] == 2:
            waveform = waveform.mean(dim=1, keepdim=True).T
        
        if sample_rate != bundle.sample_rate:
            waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)
        
        waveform = waveform.to(self.device)
        
        with torch.inference_mode():
            emissions, _ = model(waveform)
            emissions = torch.log_softmax(emissions, dim=-1)
        
        emission = emissions[0].cpu().detach()
        transcript = self._prepare_transcript(english_text, dictionary)
        tokens = [dictionary.get(c, 0) for c in transcript]
        
        trellis = self._get_trellis(emission, tokens)
        path = self._backtrack(trellis, emission, tokens)
        
        if path is None:
            print("   âš ï¸ å¼ºåˆ¶å¯¹é½å¤±è´¥")
            return []
        
        segments = self._merge_repeats(path, transcript)
        word_segments = self._chars_to_words(segments, english_text, emission.shape[0], bundle.sample_rate)
        
        print(f"   âœ… æå– {len(word_segments)} ä¸ªè¯çš„ç²¾ç¡®æ—¶é—´æˆ³")
        
        del model
        if self.device == "cuda":
            torch.cuda.empty_cache()
        
        return word_segments

    
    def _prepare_transcript(self, text: str, dictionary: dict) -> str:
        """å‡†å¤‡ç”¨äºå¯¹é½çš„è½¬å½•æ–‡æœ¬"""
        result = []
        text = text.lower()
        for char in text:
            if char == ' ':
                result.append('|')
            elif char in dictionary:
                result.append(char)
        return ''.join(result)
    
    def _get_trellis(self, emission, tokens, blank_id=0):
        """æ„å»º trellis çŸ©é˜µ"""
        num_frame = emission.size(0)
        num_tokens = len(tokens)
        trellis = torch.zeros((num_frame, num_tokens))
        trellis[1:, 0] = torch.cumsum(emission[1:, blank_id], 0)
        trellis[0, 1:] = -float("inf")
        trellis[-num_tokens + 1:, 0] = float("inf")
        for t in range(num_frame - 1):
            trellis[t + 1, 1:] = torch.maximum(
                trellis[t, 1:] + emission[t, blank_id],
                trellis[t, :-1] + emission[t, tokens[1:]],
            )
        return trellis
    
    def _backtrack(self, trellis, emission, tokens, blank_id=0):
        """å›æº¯æ‰¾åˆ°æœ€ä½³è·¯å¾„"""
        t, j = trellis.size(0) - 1, trellis.size(1) - 1
        path = [{'token_index': j, 'time_index': t, 'score': emission[t, blank_id].exp().item()}]
        while j > 0:
            if t <= 0:
                return None
            p_stay = emission[t - 1, blank_id]
            p_change = emission[t - 1, tokens[j]]
            stayed = trellis[t - 1, j] + p_stay
            changed = trellis[t - 1, j - 1] + p_change
            t -= 1
            if changed > stayed:
                j -= 1
            prob = (p_change if changed > stayed else p_stay).exp().item()
            path.append({'token_index': j, 'time_index': t, 'score': prob})
        while t > 0:
            prob = emission[t - 1, blank_id].exp().item()
            path.append({'token_index': j, 'time_index': t - 1, 'score': prob})
            t -= 1
        return path[::-1]
    
    def _merge_repeats(self, path, transcript):
        """åˆå¹¶é‡å¤çš„å­—ç¬¦"""
        segments = []
        i1, i2 = 0, 0
        while i1 < len(path):
            while i2 < len(path) and path[i1]['token_index'] == path[i2]['token_index']:
                i2 += 1
            score = sum(p['score'] for p in path[i1:i2]) / (i2 - i1)
            segments.append({
                'label': transcript[path[i1]['token_index']],
                'start': path[i1]['time_index'],
                'end': path[i2 - 1]['time_index'] + 1,
                'score': score
            })
            i1 = i2
        return segments

    
    def _chars_to_words(self, char_segments, original_text: str, num_frames: int, sample_rate: int) -> list:
        """å°†å­—ç¬¦çº§æ—¶é—´æˆ³è½¬æ¢ä¸ºè¯çº§æ—¶é—´æˆ³"""
        words = original_text.split()
        word_segments = []
        char_idx = 0
        for word in words:
            word_lower = word.lower()
            word_start = None
            word_end = None
            word_score = []
            for char in word_lower:
                if char in 'abcdefghijklmnopqrstuvwxyz':
                    while char_idx < len(char_segments):
                        seg = char_segments[char_idx]
                        if seg['label'] == char:
                            if word_start is None:
                                word_start = seg['start']
                            word_end = seg['end']
                            word_score.append(seg['score'])
                            char_idx += 1
                            break
                        elif seg['label'] == '|':
                            char_idx += 1
                        else:
                            char_idx += 1
            if word_start is not None and word_end is not None:
                frame_duration = 0.02
                word_segments.append({
                    'word': word,
                    'start': word_start * frame_duration,
                    'end': word_end * frame_duration,
                    'score': sum(word_score) / len(word_score) if word_score else 0.5
                })
            else:
                if word_segments:
                    last_end = word_segments[-1]['end']
                else:
                    last_end = 0
                word_segments.append({
                    'word': word,
                    'start': last_end,
                    'end': last_end + 0.3,
                    'score': 0.3
                })
        return word_segments


    
    def load_stories(self, story_num: int) -> tuple:
        """åŠ è½½åŸæ–‡ - è‹±æ–‡å’Œä¸­æ–‡"""
        print("ğŸ“ åŠ è½½åŸæ–‡...")
        
        eng_files = sorted(list(self.english_dir.glob("*.txt")))
        with open(eng_files[story_num - 1], 'r', encoding='utf-8') as f:
            eng_lines = f.readlines()
        
        chi_files = sorted(list(self.chinese_dir.glob("*.txt")))
        with open(chi_files[story_num - 1], 'r', encoding='utf-8') as f:
            chi_lines = f.readlines()
        
        # æå–å¥å­ï¼ˆè·³è¿‡æ ‡é¢˜å’Œç©ºè¡Œï¼‰
        # æ ¼å¼ï¼šæ ‡é¢˜ + ç©ºè¡Œ + æ¯å¥ä¸€è¡Œ
        eng_sentences = []
        chi_sentences = []
        
        # è·³è¿‡ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜ï¼‰å’Œç¬¬äºŒè¡Œï¼ˆç©ºè¡Œï¼‰
        for line in eng_lines[2:]:
            line = line.strip()
            if line:  # è·³è¿‡ç©ºè¡Œ
                eng_sentences.append(line)
        
        for line in chi_lines[2:]:
            line = line.strip()
            if line:  # è·³è¿‡ç©ºè¡Œ
                chi_sentences.append(line)
        
        print(f"   âœ… {len(eng_sentences)} ä¸ªè‹±æ–‡å¥å­")
        print(f"   âœ… {len(chi_sentences)} ä¸ªä¸­æ–‡å¥å­")
        
        # æ£€æŸ¥å¥å­æ•°é‡æ˜¯å¦åŒ¹é…
        if len(eng_sentences) != len(chi_sentences):
            print(f"   âš ï¸  è­¦å‘Š: ä¸­è‹±æ–‡å¥å­æ•°é‡ä¸åŒ¹é…!")
            print(f"      è‹±æ–‡: {len(eng_sentences)}å¥")
            print(f"      ä¸­æ–‡: {len(chi_sentences)}å¥")
        
        return eng_sentences, chi_sentences


    
    def align_sentences_with_forced_alignment(self, word_timestamps: list, eng_sentences: list, chi_sentences: list) -> list:
        """ä½¿ç”¨ Forced Alignment ç»“æœè¿›è¡Œå¥å­å¯¹é½"""
        print("ğŸ¯ ä½¿ç”¨ Forced Alignment ç»“æœå¯¹é½å¥å­...")
        
        all_original_words = []
        word_to_sentence = []
        
        for i, sent in enumerate(eng_sentences):
            words = sent.split()
            for word in words:
                all_original_words.append(word)
                word_to_sentence.append(i)
        
        print(f"   ğŸ“Š åŸæ–‡æ€»è¯æ•°: {len(all_original_words)}")
        print(f"   ğŸ“Š å¯¹é½æ—¶é—´æˆ³æ•°: {len(word_timestamps)}")
        
        if len(word_timestamps) != len(all_original_words):
            print(f"   âš ï¸ è¯æ•°ä¸å®Œå…¨åŒ¹é…ï¼Œå°è¯•æ™ºèƒ½å¯¹é½...")
            return self.align_sentences_fuzzy(word_timestamps, eng_sentences, chi_sentences, all_original_words, word_to_sentence)
        
        aligned_words = []
        for i, (word, ts) in enumerate(zip(all_original_words, word_timestamps)):
            aligned_words.append({
                'word': word,
                'start': ts['start'],
                'end': ts['end'],
                'score': ts.get('score', 1.0),
                'sentence_idx': word_to_sentence[i]
            })
        
        aligned = []
        for i, eng_sent in enumerate(eng_sentences):
            sentence_words = [w for w in aligned_words if w['sentence_idx'] == i]
            
            if sentence_words:
                start_time = sentence_words[0]['start']
                end_time = sentence_words[-1]['end']
            else:
                start_time = 0
                end_time = 0
            
            chi_text = chi_sentences[i] if i < len(chi_sentences) else ""
            
            aligned.append({
                'index': i + 1,
                'start': start_time,
                'end': end_time,
                'english': eng_sent,
                'chinese': chi_text,
                'words': sentence_words,
                'score': 1.0,
                'word_start_idx': 0,
                'word_end_idx': len(sentence_words) - 1
            })
        
        print(f"   âœ… {len(aligned)} ä¸ªå¥å­å¯¹é½å®Œæˆ")
        return aligned

    
    def align_sentences_fuzzy(self, word_timestamps: list, eng_sentences: list, chi_sentences: list, 
                               all_original_words: list, word_to_sentence: list) -> list:
        """æ¨¡ç³Šå¯¹é½"""
        print("   ğŸ”„ ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…å¯¹é½...")
        
        ts_words = [ts['word'].lower().strip('.,!?;:"\'') for ts in word_timestamps]
        aligned_words = []
        ts_idx = 0
        
        for i, orig_word in enumerate(all_original_words):
            orig_clean = orig_word.lower().strip('.,!?;:"\'')
            best_match_idx = ts_idx
            best_score = 0
            search_range = min(5, len(word_timestamps) - ts_idx)
            for j in range(search_range):
                if ts_idx + j >= len(word_timestamps):
                    break
                ts_clean = ts_words[ts_idx + j]
                if orig_clean == ts_clean:
                    score = 1.0
                elif orig_clean in ts_clean or ts_clean in orig_clean:
                    score = 0.8
                else:
                    score = SequenceMatcher(None, orig_clean, ts_clean).ratio()
                if score > best_score:
                    best_score = score
                    best_match_idx = ts_idx + j
            
            if best_match_idx < len(word_timestamps):
                ts = word_timestamps[best_match_idx]
                aligned_words.append({
                    'word': orig_word,
                    'start': ts['start'],
                    'end': ts['end'],
                    'score': best_score,
                    'sentence_idx': word_to_sentence[i]
                })
                ts_idx = best_match_idx + 1
            else:
                if aligned_words:
                    last_end = aligned_words[-1]['end']
                    aligned_words.append({
                        'word': orig_word,
                        'start': last_end,
                        'end': last_end + 0.3,
                        'score': 0.5,
                        'sentence_idx': word_to_sentence[i]
                    })
        
        aligned = []
        for i, eng_sent in enumerate(eng_sentences):
            sentence_words = [w for w in aligned_words if w['sentence_idx'] == i]
            if sentence_words:
                start_time = sentence_words[0]['start']
                end_time = sentence_words[-1]['end']
            else:
                start_time = aligned[-1]['end'] if aligned else 0
                end_time = start_time
            chi_text = chi_sentences[i] if i < len(chi_sentences) else ""
            aligned.append({
                'index': i + 1,
                'start': start_time,
                'end': end_time,
                'english': eng_sent,
                'chinese': chi_text,
                'words': sentence_words,
                'score': sum(w['score'] for w in sentence_words) / len(sentence_words) if sentence_words else 0,
                'word_start_idx': 0,
                'word_end_idx': len(sentence_words) - 1
            })
        
        print(f"   âœ… {len(aligned)} ä¸ªå¥å­å¯¹é½å®Œæˆ")
        return aligned


    
    def _calculate_sentence_height(self, segment, eng_font, chi_font, draw):
        """è®¡ç®—å¥å­çš„å®é™…é«˜åº¦ï¼ˆåŒ…æ‹¬è‹±æ–‡å’Œä¸­æ–‡çš„æ‰€æœ‰è¡Œï¼‰"""
        # æ™ºèƒ½æ¢è¡Œ - è‹±æ–‡ï¼ˆæŒ‰80%å®½åº¦æ¢è¡Œï¼‰
        max_line_width = int(self.text_width * 0.8)
        text_words = segment['english'].split()
        eng_line_count = 0
        current_line_width = 0
        
        for word in text_words:
            bbox = draw.textbbox((0, 0), word + " ", font=eng_font)
            word_width = bbox[2] - bbox[0]
            
            if current_line_width + word_width > max_line_width and current_line_width > 0:
                eng_line_count += 1
                current_line_width = word_width
            else:
                current_line_width += word_width
        
        if current_line_width > 0:
            eng_line_count += 1
        
        # æ™ºèƒ½æ¢è¡Œ - ä¸­æ–‡ï¼ˆæŒ‰80%å®½åº¦æ¢è¡Œï¼‰
        chi_text = segment['chinese']
        chi_line_count = 0
        chi_current_line = ""
        
        for char in chi_text:
            test_line = chi_current_line + char
            bbox = draw.textbbox((0, 0), test_line, font=chi_font)
            line_width = bbox[2] - bbox[0]
            
            if line_width > max_line_width and chi_current_line:
                chi_line_count += 1
                chi_current_line = char
            else:
                chi_current_line = test_line
        
        if chi_current_line:
            chi_line_count += 1
        
        # è®¡ç®—æ€»é«˜åº¦
        eng_height = eng_line_count * 60  # æ¯è¡Œè‹±æ–‡60px
        chi_height = chi_line_count * 55  # æ¯è¡Œä¸­æ–‡55px
        gap = 10  # è‹±æ–‡å’Œä¸­æ–‡ä¹‹é—´çš„é—´è·
        
        total_height = eng_height + gap + chi_height
        return total_height
    
    def create_simple_subtitle_clip(self, aligned_segments: list, total_duration: float):
        """åˆ›å»ºç®€çº¦é£æ ¼å­—å¹• - å·¦ä¾§å¸ƒå±€ï¼Œå‘ä¸Šæ»šåŠ¨ï¼ŒåŠ¨æ€é—´è·ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        
        # é¢„åŠ è½½å­—ä½“ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼Œé¿å…æ¯å¸§é‡å¤åŠ è½½ï¼‰
        print("   âš¡ é¢„åŠ è½½å­—ä½“...")
        try:
            eng_font = ImageFont.truetype("C:\\Windows\\Fonts\\arialbd.ttf", 52)
            chi_font = ImageFont.truetype("C:\\Windows\\Fonts\\simhei.ttf", 46)
        except:
            try:
                eng_font = ImageFont.truetype("C:\\Windows\\Fonts\\arial.ttf", 52)
                chi_font = ImageFont.truetype("C:\\Windows\\Fonts\\simsun.ttc", 46)
            except:
                eng_font = ImageFont.truetype("C:\\Windows\\Fonts\\simsun.ttc", 52)
                chi_font = eng_font
        
        # é¢„è®¡ç®—æ¯ä¸ªå¥å­çš„é«˜åº¦
        print("   âš¡ é¢„è®¡ç®—å¥å­é«˜åº¦...")
        temp_img = Image.new('RGBA', (self.width, self.height), (0, 0, 0, 0))
        temp_draw = ImageDraw.Draw(temp_img)
        
        for seg in aligned_segments:
            seg['height'] = self._calculate_sentence_height(seg, eng_font, chi_font, temp_draw)
        
        # é¢„è®¡ç®—æ‰€æœ‰å¥å­çš„Yä½ç½®ï¼ˆé¿å…æ¯å¸§é‡å¤è®¡ç®—ï¼‰
        print("   âš¡ é¢„è®¡ç®—å¥å­ä½ç½®...")
        all_y_positions = {}
        for current_idx in range(len(aligned_segments)):
            y_positions = {}
            cumulative_y = self.highlight_y
            
            # ä»å½“å‰å¥å­å¼€å§‹ï¼Œå‘ä¸Šè®¡ç®—
            for i in range(current_idx, -1, -1):
                y_positions[i] = cumulative_y
                if i > 0:
                    cumulative_y -= (aligned_segments[i-1]['height'] + 80)
            
            # ä»å½“å‰å¥å­å¼€å§‹ï¼Œå‘ä¸‹è®¡ç®—
            cumulative_y = self.highlight_y
            for i in range(current_idx, len(aligned_segments)):
                y_positions[i] = cumulative_y
                if i < len(aligned_segments) - 1:
                    cumulative_y += (aligned_segments[i]['height'] + 80)
            
            all_y_positions[current_idx] = y_positions
        
        print("   âœ… é¢„è®¡ç®—å®Œæˆï¼Œå¼€å§‹æ¸²æŸ“...")
        
        def make_frame(t):
            # åˆ›å»ºé€æ˜èƒŒæ™¯
            img = Image.new('RGBA', (self.width, self.height), (0, 0, 0, 0))
            draw = ImageDraw.Draw(img)
            
            # æ‰¾åˆ°å½“å‰æ’­æ”¾çš„å¥å­
            current_idx = -1
            for i, seg in enumerate(aligned_segments):
                if t >= seg['start'] and t <= seg['end']:
                    current_idx = i
                    break
            
            if current_idx == -1:
                for i, seg in enumerate(aligned_segments):
                    if t < seg['start']:
                        current_idx = max(0, i - 1)
                        break
                if current_idx == -1:
                    current_idx = len(aligned_segments) - 1
            
            # è®¡ç®—æ»šåŠ¨åç§»
            scroll_offset = 0
            if current_idx < len(aligned_segments):
                seg = aligned_segments[current_idx]
                
                if t > seg['end'] and current_idx + 1 < len(aligned_segments):
                    next_seg = aligned_segments[current_idx + 1]
                    gap_duration = next_seg['start'] - seg['end']
                    next_sentence_height = seg['height'] + 80
                    
                    if gap_duration > 0:
                        time_in_gap = t - seg['end']
                        progress = min(1.0, time_in_gap / gap_duration)
                        if progress < 0.5:
                            eased_progress = 4 * progress * progress * progress
                        else:
                            eased_progress = 1 - pow(-2 * progress + 2, 3) / 2
                        scroll_offset = eased_progress * next_sentence_height
                    else:
                        scroll_offset = next_sentence_height
            
            # ä½¿ç”¨é¢„è®¡ç®—çš„ä½ç½®
            y_positions = all_y_positions.get(current_idx, {})
            visible_range = range(max(0, current_idx - 2), min(len(aligned_segments), current_idx + 3))
            
            for i in visible_range:
                segment = aligned_segments[i]
                y_pos = y_positions.get(i, self.highlight_y) - scroll_offset
                
                if y_pos < -300 or y_pos > self.height + 300:
                    continue
                
                is_highlight = (i == current_idx) and (t >= segment['start'] and t <= segment['end'])
                
                if is_highlight:
                    self._draw_sentence_with_karaoke(draw, segment, t, y_pos, eng_font, chi_font)
                else:
                    opacity = 0.5 if i != current_idx else 0.7
                    self._draw_sentence_static(draw, segment, y_pos, eng_font, chi_font, opacity)
            
            return np.array(img)
        
        return mp.VideoClip(make_frame, duration=total_duration)
    
    def _draw_sentence_with_karaoke(self, draw, segment, current_time, y_pos, eng_font, chi_font):
        """ç»˜åˆ¶å¸¦å¡æ‹‰OKé«˜äº®çš„å¥å­ï¼ˆå·¦ä¾§å¯¹é½ï¼Œæ™ºèƒ½æ¢è¡Œï¼Œä½¿ç”¨ä¸»é¢˜é¢œè‰²ï¼‰"""
        # æ‰¾åˆ°å½“å‰é«˜äº®çš„è¯
        current_word_idx = -1
        words = segment['words']
        for i, word_info in enumerate(words):
            if current_time >= word_info['start'] and current_time <= word_info['end']:
                current_word_idx = i
                break
        
        # ä½¿ç”¨ä¸»é¢˜é¢œè‰²
        text_color = self.color_scheme['text']
        highlight_color = self.color_scheme['highlight']
        
        # æ™ºèƒ½æ¢è¡Œ - è‹±æ–‡ï¼ˆæŒ‰80%å®½åº¦æ¢è¡Œï¼‰
        max_line_width = int(self.text_width * 0.8)  # 80%å®½åº¦
        text_words = segment['english'].split()
        eng_lines = []
        current_line = []
        current_line_width = 0
        word_indices = []  # è®°å½•æ¯è¡Œçš„è¯ç´¢å¼•
        
        for word_idx, word in enumerate(text_words[:len(words)]):
            bbox = draw.textbbox((0, 0), word + " ", font=eng_font)
            word_width = bbox[2] - bbox[0]
            
            if current_line_width + word_width > max_line_width and current_line:
                eng_lines.append(current_line)
                word_indices.append(list(range(len(word_indices) * 10, len(word_indices) * 10 + len(current_line))))
                current_line = [word]
                current_line_width = word_width
            else:
                current_line.append(word)
                current_line_width += word_width
        
        if current_line:
            eng_lines.append(current_line)
        
        # ç»˜åˆ¶è‹±æ–‡ï¼ˆé€è¯é«˜äº®ï¼Œå¤šè¡Œï¼‰
        y_offset = int(y_pos)
        word_idx = 0
        
        for line_words in eng_lines:
            x_offset = self.left_margin
            
            for word in line_words:
                if word_idx == current_word_idx:
                    # é«˜äº®è¯ - ä½¿ç”¨ä¸»é¢˜é«˜äº®è‰²
                    color = highlight_color
                else:
                    # æ™®é€šè¯ - ä½¿ç”¨ä¸»é¢˜æ–‡å­—è‰²
                    color = text_color
                
                draw.text((x_offset, y_offset), word, font=eng_font, fill=color)
                bbox = draw.textbbox((0, 0), word + " ", font=eng_font)
                word_width = bbox[2] - bbox[0]
                x_offset += word_width
                word_idx += 1
            
            y_offset += 60  # è¡Œé—´è·
        
        # è‹±æ–‡å’Œä¸­æ–‡ä¹‹é—´çš„é—´è·
        y_offset += 10
        
        # æ™ºèƒ½æ¢è¡Œ - ä¸­æ–‡ï¼ˆæŒ‰80%å®½åº¦æ¢è¡Œï¼‰
        chi_text = segment['chinese']
        chi_lines = []
        chi_current_line = ""
        
        for char in chi_text:
            test_line = chi_current_line + char
            bbox = draw.textbbox((0, 0), test_line, font=chi_font)
            line_width = bbox[2] - bbox[0]
            
            if line_width > max_line_width and chi_current_line:
                chi_lines.append(chi_current_line)
                chi_current_line = char
            else:
                chi_current_line = test_line
        
        if chi_current_line:
            chi_lines.append(chi_current_line)
        
        # ç»˜åˆ¶ä¸­æ–‡ï¼ˆå¤šè¡Œï¼Œä½¿ç”¨ä¸»é¢˜æ–‡å­—è‰²ï¼‰
        for chi_line in chi_lines:
            draw.text((self.left_margin, y_offset), chi_line, font=chi_font, fill=text_color)
            y_offset += 55  # è¡Œé—´è·
    
    def _draw_sentence_static(self, draw, segment, y_pos, eng_font, chi_font, opacity):
        """ç»˜åˆ¶é™æ€å¥å­ï¼ˆå·¦ä¾§å¯¹é½ï¼ŒåŠé€æ˜ï¼Œæ™ºèƒ½æ¢è¡Œï¼Œä½¿ç”¨ä¸»é¢˜é¢œè‰²ï¼‰"""
        # ä½¿ç”¨ä¸»é¢˜æ–‡å­—é¢œè‰²
        color = self.color_scheme['text']
        alpha = int(255 * opacity)
        color_with_alpha = (*color, alpha)
        
        # æ™ºèƒ½æ¢è¡Œ - è‹±æ–‡ï¼ˆæŒ‰80%å®½åº¦æ¢è¡Œï¼‰
        max_line_width = int(self.text_width * 0.8)  # 80%å®½åº¦
        text_words = segment['english'].split()
        eng_lines = []
        current_line = []
        current_line_width = 0
        
        for word in text_words:
            bbox = draw.textbbox((0, 0), word + " ", font=eng_font)
            word_width = bbox[2] - bbox[0]
            
            if current_line_width + word_width > max_line_width and current_line:
                eng_lines.append(' '.join(current_line))
                current_line = [word]
                current_line_width = word_width
            else:
                current_line.append(word)
                current_line_width += word_width
        
        if current_line:
            eng_lines.append(' '.join(current_line))
        
        # ç»˜åˆ¶è‹±æ–‡ï¼ˆå¤šè¡Œï¼‰
        y_offset = int(y_pos)
        for line in eng_lines:
            draw.text((self.left_margin, y_offset), line, font=eng_font, fill=color_with_alpha)
            y_offset += 60  # è¡Œé—´è·
        
        # è‹±æ–‡å’Œä¸­æ–‡ä¹‹é—´çš„é—´è·
        y_offset += 10
        
        # æ™ºèƒ½æ¢è¡Œ - ä¸­æ–‡ï¼ˆæŒ‰80%å®½åº¦æ¢è¡Œï¼‰
        chi_text = segment['chinese']
        chi_lines = []
        chi_current_line = ""
        
        for char in chi_text:
            test_line = chi_current_line + char
            bbox = draw.textbbox((0, 0), test_line, font=chi_font)
            line_width = bbox[2] - bbox[0]
            
            if line_width > max_line_width and chi_current_line:
                chi_lines.append(chi_current_line)
                chi_current_line = char
            else:
                chi_current_line = test_line
        
        if chi_current_line:
            chi_lines.append(chi_current_line)
        
        # ç»˜åˆ¶ä¸­æ–‡ï¼ˆå¤šè¡Œï¼‰
        for chi_line in chi_lines:
            draw.text((self.left_margin, y_offset), chi_line, font=chi_font, fill=color_with_alpha)
            y_offset += 55  # è¡Œé—´è·


    
    def create_simple_background(self, duration: float) -> mp.VideoClip:
        """åˆ›å»ºç®€çº¦èƒŒæ™¯ - ä½¿ç”¨ä¸»é¢˜é¢œè‰²ï¼ˆä¸“ä¸šå»è‰²å¸¦ç‰ˆæœ¬ï¼‰"""
        print("ğŸ¨ åˆ›å»ºç®€çº¦èƒŒæ™¯ï¼ˆä¸“ä¸šå»è‰²å¸¦ï¼‰...")
        
        import random
        
        # ä½¿ç”¨numpyåˆ›å»ºè¶…å¹³æ»‘æ¸å˜
        color_start = np.array(self.color_scheme['bg_start'], dtype=np.float64)
        color_end = np.array(self.color_scheme['bg_end'], dtype=np.float64)
        
        # åˆ›å»ºé«˜ç²¾åº¦æ¸å˜æ•°ç»„
        gradient = np.zeros((self.height, self.width, 3), dtype=np.float64)
        
        # ä½¿ç”¨è¶…å¹³æ»‘çš„æ¸å˜å‡½æ•°ï¼ˆsmootherstep - æ¯”smoothstepæ›´å¹³æ»‘ï¼‰
        for y in range(self.height):
            ratio = y / self.height
            # smootherstep: 6t^5 - 15t^4 + 10t^3
            smooth_ratio = ratio * ratio * ratio * (ratio * (ratio * 6 - 15) + 10)
            color = color_start * (1 - smooth_ratio) + color_end * smooth_ratio
            gradient[y, :] = color
        
        # æ·»åŠ BayerçŸ©é˜µæŠ–åŠ¨ï¼ˆä¸“ä¸šå»è‰²å¸¦æŠ€æœ¯ï¼‰
        # 8x8 BayerçŸ©é˜µ
        bayer_matrix = np.array([
            [ 0, 32,  8, 40,  2, 34, 10, 42],
            [48, 16, 56, 24, 50, 18, 58, 26],
            [12, 44,  4, 36, 14, 46,  6, 38],
            [60, 28, 52, 20, 62, 30, 54, 22],
            [ 3, 35, 11, 43,  1, 33,  9, 41],
            [51, 19, 59, 27, 49, 17, 57, 25],
            [15, 47,  7, 39, 13, 45,  5, 37],
            [63, 31, 55, 23, 61, 29, 53, 21]
        ], dtype=np.float64) / 64.0 - 0.5  # å½’ä¸€åŒ–åˆ°[-0.5, 0.5]
        
        # åˆ›å»ºå…¨å°ºå¯¸çš„æŠ–åŠ¨çŸ©é˜µ
        tile_h = self.height // 8 + 1
        tile_w = self.width // 8 + 1
        dither = np.tile(bayer_matrix, (tile_h, tile_w))[:self.height, :self.width]
        dither = dither[:, :, np.newaxis]  # æ·»åŠ é¢œè‰²é€šé“ç»´åº¦
        dither = np.repeat(dither, 3, axis=2)  # æ‰©å±•åˆ°3ä¸ªé¢œè‰²é€šé“
        
        # åº”ç”¨æŠ–åŠ¨ï¼ˆå¼ºåº¦ä¸º4.0ï¼Œæ›´å¼ºçš„å»è‰²å¸¦æ•ˆæœï¼‰
        gradient_dithered = gradient + dither * 4.0
        
        # è½¬æ¢ä¸ºuint8
        gradient_uint8 = np.clip(gradient_dithered, 0, 255).astype(np.uint8)
        
        # éå¸¸è½»å¾®çš„é«˜æ–¯æ¨¡ç³Šï¼ˆ0.3sigmaï¼Œå‡ ä¹çœ‹ä¸å‡ºæ¨¡ç³Šä½†èƒ½æŸ”åŒ–æŠ–åŠ¨ï¼‰
        gradient_final = cv2.GaussianBlur(gradient_uint8, (3, 3), 0.3)
        
        # è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä¿å­˜ï¼ˆä½¿ç”¨æœ€é«˜è´¨é‡ï¼‰
        img = Image.fromarray(gradient_final, mode='RGB')
        bg_path = str(self.temp_dir / "bg_simple.png")
        img.save(bg_path, quality=100, optimize=False)
        
        # å°æ˜Ÿæ˜Ÿç²’å­ï¼ˆåªåœ¨å·¦ä¾§åŒºåŸŸï¼Œä½¿ç”¨ä¸»é¢˜é¢œè‰²ï¼‰
        num_stars = 50
        stars = []
        for i in range(num_stars):
            stars.append({
                'x': random.randint(self.left_margin, self.width - self.right_safe_zone),
                'y': random.randint(100, self.height - 100),
                'size': random.choice([1, 1, 2, 2, 3]),
                'speed': random.uniform(0.5, 2.0),
                'phase': random.uniform(0, 2 * np.pi)
            })
        
        def make_frame(t):
            bg = cv2.imread(bg_path)
            bg = cv2.resize(bg, (self.width, self.height))
            
            # ä½¿ç”¨ä¸»é¢˜æ˜Ÿå…‰é¢œè‰²
            star_color = self.color_scheme['star']
            sr, sg, sb = star_color
            
            for star in stars:
                brightness = 0.5 + 0.5 * np.sin(t * star['speed'] * 2 * np.pi + star['phase'])
                x = star['x']
                y = int(star['y'] + 15 * np.sin(t * star['speed'] + star['phase']))
                size = star['size']
                
                if self.left_margin <= x < self.width - self.right_safe_zone and 100 <= y < self.height - 100:
                    if size == 1:
                        bg[y, x] = [int(sb * brightness), int(sg * brightness), int(sr * brightness)]
                    elif size == 2:
                        for dx, dy in [(0,0), (1,0), (-1,0), (0,1), (0,-1)]:
                            nx, ny = x + dx, y + dy
                            if self.left_margin <= nx < self.width - self.right_safe_zone and 100 <= ny < self.height - 100:
                                bg[ny, nx] = [int(sb * brightness), int(sg * brightness), int(sr * brightness)]
                    else:
                        for dx in range(-2, 3):
                            for dy in range(-2, 3):
                                if abs(dx) + abs(dy) <= 2:
                                    nx, ny = x + dx, y + dy
                                    if self.left_margin <= nx < self.width - self.right_safe_zone and 100 <= ny < self.height - 100:
                                        fade = 1 - (abs(dx) + abs(dy)) * 0.15
                                        bg[ny, nx] = [int(sb * brightness * fade), 
                                                     int(sg * brightness * fade), 
                                                     int(sr * brightness * fade)]
            
            return cv2.cvtColor(bg, cv2.COLOR_BGR2RGB)
        
        return mp.VideoClip(make_frame, duration=duration)

    
    def get_color_scheme(self, story_num: int) -> dict:
        """è·å–é¢œè‰²æ–¹æ¡ˆ - ä¸ç”µè„‘ç‰ˆä¿æŒä¸€è‡´"""
        import random
        random.seed(story_num)
        
        # 8ä¸ªä¸»é¢˜é…è‰²æ–¹æ¡ˆï¼ˆä¸ç”µè„‘ç‰ˆå®Œå…¨ä¸€è‡´ï¼‰
        schemes = [
            {
                'name': 'å†°è“æå…‰',
                'bg_start': (10, 20, 50),
                'bg_end': (30, 60, 100),
                'text': (220, 220, 255),
                'highlight': (255, 182, 193),
                'star': (180, 220, 255),
            },
            {
                'name': 'æ¢¦å¹»ç´«ç½—å…°',
                'bg_start': (30, 10, 50),
                'bg_end': (50, 20, 80),
                'text': (220, 220, 255),
                'highlight': (255, 182, 193),
                'star': (200, 180, 255),
            },
            {
                'name': 'ç¿¡ç¿ æå…‰',
                'bg_start': (5, 25, 20),
                'bg_end': (15, 50, 40),
                'text': (220, 255, 240),
                'highlight': (255, 255, 150),
                'star': (180, 255, 220),
            },
            {
                'name': 'çƒˆç„°çº¢',
                'bg_start': (40, 10, 10),
                'bg_end': (60, 15, 15),
                'text': (255, 220, 220),
                'highlight': (255, 255, 100),
                'star': (255, 200, 150),
            },
            {
                'name': 'é‡‘è‰²æš–é˜³',
                'bg_start': (40, 20, 10),
                'bg_end': (60, 30, 15),
                'text': (255, 240, 220),
                'highlight': (255, 255, 255),
                'star': (255, 220, 180),
            },
            {
                'name': 'è–°è¡£è‰æ¢¦',
                'bg_start': (25, 20, 40),
                'bg_end': (40, 35, 60),
                'text': (240, 230, 255),
                'highlight': (255, 200, 255),
                'star': (220, 200, 255),
            },
            {
                'name': 'æµ·æ´‹æ·±è“',
                'bg_start': (5, 15, 35),
                'bg_end': (10, 25, 50),
                'text': (200, 230, 255),
                'highlight': (150, 255, 255),
                'star': (150, 200, 255),
            },
            {
                'name': 'æ£®æ—ç»¿æ„',
                'bg_start': (10, 25, 15),
                'bg_end': (15, 35, 20),
                'text': (230, 255, 230),
                'highlight': (255, 255, 150),
                'star': (180, 230, 190),
            },
        ]
        
        # ç¬¬ä¸€ä¸ªæ•…äº‹å›ºå®šç”¨å†°è“æå…‰
        if story_num == 1:
            return schemes[0]
        else:
            return schemes[(story_num - 1) % len(schemes)]
    
    def generate(self, story_num: int = 1, use_forced_alignment: bool = True, theme_override: int = None):
        """ç”Ÿæˆå¡æ‹‰OKè§†é¢‘ - ç®€çº¦é£æ ¼
        
        Args:
            story_num: æ•…äº‹ç¼–å·
            use_forced_alignment: æ˜¯å¦ä½¿ç”¨å¼ºåˆ¶å¯¹é½
            theme_override: å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šä¸»é¢˜ (1-8)ï¼ŒNoneåˆ™æŒ‰story_numè‡ªåŠ¨é€‰æ‹©
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“± ç”Ÿæˆæ•…äº‹ {story_num} - æ‰‹æœºç«–å±ç‰ˆ V3 (ç®€çº¦é£æ ¼)")
        print(f"{'='*60}\n")
        
        # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ
        if theme_override is not None:
            self.color_scheme = self.get_color_scheme(theme_override)
        else:
            self.color_scheme = self.get_color_scheme(story_num)
        
        print("ç‰¹ç‚¹:")
        print("  ğŸ“± ç«–å±æ ¼å¼ - 1080x1920 (9:16)")
        print("  ğŸ“ å·¦ä¾§å¸ƒå±€ - é¿å¼€å³ä¾§æŒ‰é’®")
        print("  â¬†ï¸ å‘ä¸Šæ»šåŠ¨ - é«˜å…‰å›ºå®šåœ¨å·¦ä¸­")
        print("  ğŸ¨ ç®€çº¦é£æ ¼ - ç´«è‰²èƒŒæ™¯ + ç™½è‰²å­—")
        print("  âœ¨ å°æ˜Ÿæ˜Ÿ - å·¦ä¾§åŒºåŸŸ")
        print("  ğŸ¤ è¯çº§å¡æ‹‰OK - ç²‰è‰²é«˜äº®")
        print("  ğŸ¯ Forced Alignment - ç²¾ç¡®å¯¹é½")
        print(f"  ğŸ¨ é…è‰²æ–¹æ¡ˆ - {self.color_scheme['name']}")
        
        # åŠ è½½åŸæ–‡
        eng_sentences, chi_sentences = self.load_stories(story_num)
        
        # è·å–éŸ³é¢‘
        audio_files = sorted(list(self.audio_dir.glob("*.wav")))
        if not audio_files:
            audio_files = sorted(list(self.audio_dir.glob("*.mp3")))
        audio_path = str(audio_files[story_num - 1])
        
        # æå–è¯çº§æ—¶é—´æˆ³
        if use_forced_alignment:
            full_english_text = ' '.join(eng_sentences)
            word_timestamps = self.extract_word_timestamps_with_forced_alignment(audio_path, full_english_text)
            aligned = self.align_sentences_with_forced_alignment(word_timestamps, eng_sentences, chi_sentences)
        else:
            print("   âš ï¸ å¿…é¡»ä½¿ç”¨ Forced Alignment")
            return
        
        # åˆ›å»ºå­—å¹•
        print("\nğŸ¬ åˆ›å»ºç®€çº¦å­—å¹•...")
        audio_clip = mp.AudioFileClip(audio_path)
        duration = audio_clip.duration
        
        subtitle_clip = self.create_simple_subtitle_clip(aligned, duration)
        print(f"   âœ… ç®€çº¦å­—å¹•åˆ›å»ºå®Œæˆ")
        
        # åˆ›å»ºèƒŒæ™¯
        background = self.create_simple_background(duration)
        
        # åˆæˆ
        print("\nğŸ¬ åˆæˆæœ€ç»ˆè§†é¢‘...")
        final = mp.CompositeVideoClip([background, subtitle_clip])
        final = final.with_audio(audio_clip)
        
        # è¾“å‡º
        output_path = self.output_dir / f"Story_{story_num:02d}_Karaoke_Mobile_V3_Simple.mp4"
        
        print(f"\nâš¡ ä½¿ç”¨æ— æŸç¼–ç ï¼ˆå®Œå…¨æ— è‰²å¸¦ï¼Œæ–‡ä»¶è¾ƒå¤§ï¼‰...")
        final.write_videofile(
            str(output_path),
            fps=60,  # 60fpsæµç•…åŠ¨ç”»
            codec='libx264',
            audio_codec='aac',
            preset='veryslow',  # æœ€æ…¢ç¼–ç ï¼Œæœ€é«˜è´¨é‡
            threads=8,
            ffmpeg_params=[
                '-crf', '0',  # CRF 0 = å®Œå…¨æ— æŸ
                '-pix_fmt', 'yuv444p',  # 4:4:4è‰²åº¦é‡‡æ ·ï¼Œæ— è‰²åº¦å‹ç¼©
                '-qp', '0',  # é‡åŒ–å‚æ•°0 = æ— æŸ
                '-movflags', '+faststart'
            ]
        )
        
        print(f"\nâœ… å®Œæˆï¼è§†é¢‘å·²ä¿å­˜: {output_path}")
        print(f"   å°ºå¯¸: {self.width}x{self.height} (9:16 ç«–å±)")
        print(f"   æ—¶é•¿: {duration:.1f}ç§’")
        print(f"   é£æ ¼: ç®€çº¦é£æ ¼ (å¿«æ‰‹/æŠ–éŸ³ä¼˜åŒ–)")
        print(f"   å¸ƒå±€: å·¦ä¾§å¸ƒå±€ï¼Œé¿å¼€å³ä¾§æŒ‰é’®")


if __name__ == "__main__":
    generator = KaraokeAlignmentGeneratorMobileV3Simple()
    generator.generate(story_num=2, use_forced_alignment=True, theme_override=1)  # Story 2 ä½¿ç”¨å†°è“æå…‰ä¸»é¢˜
